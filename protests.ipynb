{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial imports and declarations\n",
    "Will be expanded later to include a bevy of imports for various processing, data exploration, and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                #core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "\n",
    "#models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "#post-modelling metrics\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"protests.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Structures \n",
    "Includes function declarations, lists, dictionaries, etc. that are used later in the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_drops = [\n",
    "    '1_accomodation', '1_arrests', '1_beatings', '1_crowd dispersal', '1_ignore', '1_killings', '1_shootings',\n",
    "    '2_accomodation', '2_arrests', '2_beatings', '2_crowd dispersal', '2_ignore', '2_killings', '2_shootings', \n",
    "    '3_accomodation', '3_arrests', '3_beatings', '3_crowd dispersal', '3_ignore', '3_killings', '3_shootings', \n",
    "    '4_accomodation', '4_arrests', '4_beatings', '4_crowd dispersal', '4_killings', '4_shootings', \n",
    "    '5_.', '5_accomodation', '5_arrests', '5_beatings', '5_crowd dispersal', '5_killings', '5_shootings', \n",
    "    '6_accomodation', '6_arrests', '6_beatings', '6_crowd dispersal', '6_killings', \n",
    "    '7_.', '7_accomodation', '7_arrests', '7_beatings', '7_killings'\n",
    "]\n",
    "\n",
    "demand_drops = [\n",
    "    'demand1_labor wage dispute', 'demand1_land farm issue', 'demand1_police brutality', 'demand1_political behavior, process', 'demand1_price increases, tax policy', 'demand1_removal of politician', 'demand1_social restrictions', \n",
    "    'demand2_labor wage dispute', 'demand2_land farm issue', 'demand2_police brutality', 'demand2_political behavior, process', 'demand2_price increases, tax policy', 'demand2_removal of politician', 'demand2_social restrictions', \n",
    "    'demand3_labor wage dispute', 'demand3_land farm issue', 'demand3_police brutality', 'demand3_political behavior, process', 'demand3_price increases, tax policy', 'demand3_removal of politician', 'demand3_social restrictions', \n",
    "    'demand4_.', 'demand4_labor wage dispute', 'demand4_land farm issue', 'demand4_police brutality', 'demand4_political behavior, process', 'demand4_price increases, tax policy', 'demand4_removal of politician'\n",
    "]\n",
    "\n",
    "time_drops = ['startday', 'startmonth', 'startyear', 'endday', 'endmonth', 'endyear']\n",
    "\n",
    "other_drops = [\n",
    "    'id', #Not useful to prediction.\n",
    "    'ccode', #Not useful to prediction.\n",
    "    'protest', #All values are 1.  Is this dataset the subset of another?\n",
    "    'protestnumber', # of protests per country might be useful but not in the context of incremental numbers that it's being given\n",
    "    'location', #Not extremely useable given how it's already being broken by region.\n",
    "    'participants_category', #Too many null values to be of great value.\n",
    "]\n",
    "\n",
    "demands = ['protesterdemand1', 'protesterdemand2', 'protesterdemand3', 'protesterdemand4']\n",
    "\n",
    "response = [\"stateresponse1\", \"stateresponse2\", \"stateresponse3\", \"stateresponse4\", \"stateresponse5\", \"stateresponse6\", \"stateresponse7\"]\n",
    "\n",
    "targets = ['y_accomodation', 'y_arrests', 'y_beatings', 'y_crowd dispersal', 'y_ignore', 'y_killings', 'y_shootings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_texts(x):\n",
    "    x = x.lower()\n",
    "    \n",
    "    if x == \"dozens\":\n",
    "        return 50\n",
    "    elif x == \"hundreds\":\n",
    "        return 500\n",
    "    elif x == \"thousands\":\n",
    "        return 5000\n",
    "    elif x == \"tens of thousands\":\n",
    "        return 50000\n",
    "    elif \"hundreds of thousands\" in x:\n",
    "        return 250000\n",
    "    elif \"millions\" in x:\n",
    "        return 2000000\n",
    "    elif \"million\" in x:\n",
    "        return 1000000\n",
    "    \n",
    "    \n",
    "    elif \"about \" in x:\n",
    "        return x[6:]\n",
    "    elif \"more than \" in x:\n",
    "        return x[10:]\n",
    "    \n",
    "    \n",
    "    elif \"several\" in x:\n",
    "        if \"dozen\" in x:\n",
    "            return 50\n",
    "        elif \"hundred\" in x:\n",
    "            return 500\n",
    "        elif \"thousand\" in x:\n",
    "            return 5000\n",
    "    \n",
    "    \n",
    "    elif \"hundreds\" in x:\n",
    "        return 500\n",
    "    elif \"thousands\" in x:\n",
    "        return 5000\n",
    "    \n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def strip_chars(x):\n",
    "    banned_chars = \"+s><,\"\n",
    "    x = \"\".join([c for c in x if c not in banned_chars])\n",
    "    \n",
    "    try:\n",
    "        x = int(x)\n",
    "    finally:\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "def avg_hyphen(x):\n",
    "    accepted_chars = \"1234567890-\"\n",
    "    ind = 0\n",
    "\n",
    "    x = \"\".join([c for c in x if c in accepted_chars])\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        if x[i] == \"-\":\n",
    "            ind = i\n",
    "    \n",
    "    lower = x[:ind]\n",
    "    upper = x[ind+1:]\n",
    "    \n",
    "    if (lower == \"\") or (upper==\"\"):\n",
    "        return np.nan\n",
    "    \n",
    "    return (int(lower) + int(upper)) /2\n",
    "    \n",
    "    \n",
    "    \n",
    "def map_participants(x):\n",
    "    while type(x) == str:\n",
    "        x = parse_texts(x)\n",
    "        if type(x) == str:\n",
    "            x = strip_chars(x)\n",
    "        if type(x) == str:\n",
    "            x = avg_hyphen(x)\n",
    "        if type(x) == str:\n",
    "            x = np.nan\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Cleaning\n",
    "Contains blocks of code for known cleaning problems derived from any previous data exploration.\n",
    "\n",
    "To-do:\n",
    "1. Dummify and verticalize protestor demands.\n",
    "2. Rectify the participants_category, participants columns\n",
    "3. Get \"protest length\" as a feature\n",
    "4. drop id, ccode, protestnumber(?), sources(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General/Miscellaneous Cleaning\n",
    "\n",
    "df.dropna(subset=[\"notes\"], inplace=True) #If there are no notes, then we will not be able to predict the outcome very well.\n",
    "df.dropna(subset=[\"participants\"], inplace=True) #Participants had very few NaN values\n",
    "df.dropna(subset=[\"sources\"], inplace=True) #Sources had very few NaN values\n",
    "\n",
    "\n",
    "#Miscellaneous useless feature cleaning.  See the list declaration [other_drops] in DATA STRUCTURES for additional information.\n",
    "df.drop(columns=other_drops, inplace=True)\n",
    "\n",
    "\n",
    "#For the 500 or so values containing NaN in protestor identity:\n",
    "df.fillna(value={\"protesteridentity\":\"unspecified\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#For fixing the time values such that a length of time (in days) for the protest is established as a feature, and other time features are dropped.\n",
    "#Critically, the year the protest initially occured is retained in another column.\n",
    "\n",
    "month_days = {1:0, 2:31, 3:59, 4:90, 5:120, 6:151, 7:181, 8:212, 9:243, 10:273, 11:304, 12:334}\n",
    "df[\"protest_length\"] = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    yearday_start = month_days[df[\"startmonth\"].iloc[i]] + df[\"startday\"].iloc[i]\n",
    "    yearday_end = month_days[df[\"endmonth\"].iloc[i]] + df[\"endday\"].iloc[i]\n",
    "    \n",
    "    difference = (yearday_end - yearday_start) + (365 * (df[\"endyear\"].iloc[i] - df[\"startyear\"].iloc[i]))\n",
    "    \n",
    "    if difference != 0:\n",
    "        df[\"protest_length\"].iloc[i] = difference\n",
    "    else:\n",
    "        df[\"protest_length\"].iloc[i] = 1 #accounts for same-day protests\n",
    "\n",
    "\n",
    "#Now that the length is obtained, the additional time columns can be dropped.\n",
    "df.drop(columns=time_drops, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For fixing the Participants feature such that we have a numerical value.\n",
    "#For more information, see the function map_participants() in DATA STRUCTURES.\n",
    "df[\"participants\"] = df[\"participants\"].map(map_participants)\n",
    "\n",
    "df.dropna(subset=[\"participants\"], inplace=True) #150 null values remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For translating the vertical state response & the protester demands values laterally.\n",
    "\n",
    "\n",
    "df = pd.get_dummies(data=df, prefix=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], columns=response)\n",
    "df = pd.get_dummies(data=df, prefix=[\"demand1\", \"demand2\", \"demand3\", \"demand4\"], columns=demands)\n",
    "\n",
    "\n",
    "#Combining the disparate dummies into unified response columns.  \n",
    "#Unfortunately there was a certain amount of manual labor involved in this due to how finicky pandas is.\n",
    "df[\"demand_labor_wage_dispute\"] = df['demand1_labor wage dispute'] + df['demand2_labor wage dispute'] + df['demand3_labor wage dispute'] + df['demand4_labor wage dispute']\n",
    "df[\"demand_land_farm_issue\"] = df['demand1_land farm issue'] + df['demand2_land farm issue'] + df['demand3_land farm issue'] + df['demand4_land farm issue']\n",
    "df[\"demand_police_brutality\"] = df['demand1_police brutality'] + df['demand2_police brutality'] + df['demand3_police brutality'] + df['demand4_police brutality']\n",
    "df[\"demand_political_behavior_or_process\"] = df['demand1_political behavior, process'] + df['demand2_political behavior, process'] + df['demand3_political behavior, process'] + df['demand4_political behavior, process']\n",
    "df[\"demand_price_hike_or_tax_policy\"] = df['demand1_price increases, tax policy'] + df['demand2_price increases, tax policy'] + df['demand3_price increases, tax policy'] + df['demand4_price increases, tax policy']\n",
    "df[\"demand_removal_of_politician\"] = df['demand1_removal of politician'] + df['demand2_removal of politician'] + df['demand3_removal of politician'] + df['demand4_removal of politician']\n",
    "df[\"demand_social_restrictions\"] = df['demand1_social restrictions'] + df['demand2_social restrictions'] + df['demand3_social restrictions']\n",
    "\n",
    "df[\"y_accomodation\"] = df['1_accomodation'] + df['2_accomodation'] + df['3_accomodation'] + df['4_accomodation'] + df['5_accomodation'] + df['6_accomodation'] + df['7_accomodation']\n",
    "df[\"y_arrests\"] = df['1_arrests'] + df['2_arrests'] + df['3_arrests'] + df['4_arrests'] + df['5_arrests'] + df['6_arrests'] + df['7_arrests']\n",
    "df[\"y_beatings\"] = df['1_beatings'] + df['2_beatings'] + df['3_beatings'] + df['4_beatings'] + df['5_beatings'] + df['6_beatings'] + df['7_beatings']\n",
    "df[\"y_crowd_dispersal\"] = df['1_crowd dispersal'] + df['2_crowd dispersal'] + df['3_crowd dispersal'] + df['4_crowd dispersal'] + df['5_crowd dispersal'] + df['6_crowd dispersal']\n",
    "df[\"y_ignore\"] = df['1_ignore'] + df['2_ignore'] + df['3_ignore']\n",
    "df[\"y_killings\"] = df['1_killings'] + df['2_killings'] + df['3_killings'] + df['4_killings'] + df['5_killings'] + df['6_killings'] + df['7_killings']\n",
    "df[\"y_shootings\"] = df['1_shootings'] + df['2_shootings'] + df['3_shootings'] + df['4_shootings'] + df['5_shootings']\n",
    "\n",
    "\n",
    "\n",
    "#Getting rid of the disparate dummies now that we have unified responses.\n",
    "df.drop(columns=response_drops, inplace=True)\n",
    "df.drop(columns=demand_drops, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, dropping Oceania due to the limited number of entries for that region.\n",
    "df = df[df[\"region\"] != \"Oceania\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data exploration & analysis\n",
    "Find problems to address here and then address them in the data cleaning section.  Or, create graphs or other data exploration methods here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14264 entries, 0 to 16312\n",
      "Data columns (total 23 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   country                               14264 non-null  object \n",
      " 1   year                                  14264 non-null  int64  \n",
      " 2   region                                14264 non-null  object \n",
      " 3   protesterviolence                     14264 non-null  float64\n",
      " 4   participants                          14264 non-null  float64\n",
      " 5   protesteridentity                     14264 non-null  object \n",
      " 6   sources                               14264 non-null  object \n",
      " 7   notes                                 14264 non-null  object \n",
      " 8   protest_length                        14264 non-null  float64\n",
      " 9   demand_labor_wage_dispute             14264 non-null  uint8  \n",
      " 10  demand_land_farm_issue                14264 non-null  uint8  \n",
      " 11  demand_police_brutality               14264 non-null  uint8  \n",
      " 12  demand_political_behavior_or_process  14264 non-null  uint8  \n",
      " 13  demand_price_hike_or_tax_policy       14264 non-null  uint8  \n",
      " 14  demand_removal_of_politician          14264 non-null  uint8  \n",
      " 15  demand_social_restrictions            14264 non-null  uint8  \n",
      " 16  y_accomodation                        14264 non-null  uint8  \n",
      " 17  y_arrests                             14264 non-null  uint8  \n",
      " 18  y_beatings                            14264 non-null  uint8  \n",
      " 19  y_crowd_dispersal                     14264 non-null  uint8  \n",
      " 20  y_ignore                              14264 non-null  uint8  \n",
      " 21  y_killings                            14264 non-null  uint8  \n",
      " 22  y_shootings                           14264 non-null  uint8  \n",
      "dtypes: float64(3), int64(1), object(5), uint8(14)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Protests by Region'}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp4AAAE/CAYAAADv3sNFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhMElEQVR4nO3de5xdZX3v8c/XBANyUwFtBGSsjVLKJWpQEAREtGisgKASqQVrTW291eOlqEfF1kqOvaFHW40UAauCFUUUq3hQRMQCCSQEEPBCvEQq2GAKClTD7/yxn5HNODNJJsnamZnP+/Xar1nrWetZ67f288J8fdZaM6kqJEmSpM3tQYMuQJIkSdODwVOSJEmdMHhKkiSpEwZPSZIkdcLgKUmSpE4YPCVJktQJg6ckTQFJTknyr4OuYzxJHp3kriQzBl2LpMEweEqalpKsTHJ3C0I/SfKRJNtN8FiV5Hc2QU1bRHgc8d38Z5IzJ/rd9KuqH1TVdlW1dlPUKWnyMXhKms7+oKq2A54I7A/875E7JJnZeVVbhuHvZi7wBODNgy1H0lRg8JQ07VXVKuDfgb3h1zOYr0zybeDbre3lSb6TZHWSC5I8qrVf2g6zvM0Qvqi1PzfJsiQ/S3J5kn2Hz5fkL5OsSnJnkpuSPCPJkcBbgBe14yxv+56U5Htt31uSnDDOpWyd5Ny279VJ9mvHeGOS8/p3TPJ/k5y2Ht/NfwJfohdAh/se0K7pZ0mWJzmsb9tjklzaavh/ST4wPIubZKh9tzPb+qPad7m6fbcv7zvOKUk+meTsdqzrk8xbV72StmwGT0nTXpLdgecA1/Q1Hw08BdgryeHAqcALgdnA94FzAKrqkLb/fu028rlJngicAfwpsBPwIeCCJLOSPB54FbB/VW0P/D6wsqq+CLwbOLcdZ78k2wLvA57d9n0qsGycSzkK+Dfg4cDHgfOTbAX8K3Bkkoe2650JvAj46Hp8N7sBzwa+09Z3BS4E3tXO8wbgvCS7tC4fB65s130K8JJxDv8J4EfAo4DjgHcneUbf9ufR+54fClwAvH9d9Urashk8JU1n5yf5GXAZ8DV6wW/YqVW1uqruBk4Azqiqq6vqXnq3nQ9MMjTGcV8OfKiqrqiqtVV1FnAvcACwFphFL9BuVVUrq+q749R4H7B3km2q6taqun6cfZdW1aeq6pfAPwBbAwdU1a3ApcAL2n5HAj+tqqXjHOv8JHcCPwRuA97R2v8Q+EJVfaGq7quqLwNLgOckeTS9RxbeXlX/U1WX0QuMv6GF/YOBv6yqe6pqGXA6Dwyql7XzrKUXkvcbp15Jk4DBU9J0dnRVPbSq9qiqP28hc9gP+5YfRW+WE4Cqugv4L2DXMY67B/D6div6Zy3c7g48qqq+A/wFvdnA25KcM3zbfqSq+jm9mclXALcmuTDJnuNcz69rrqr7uH82EeAseqGR9nNds51Ht1nWw4A9gZ37ru0FI67tYHozwY8CVlfVL0araYThfe/sa/s+D/xO/7Nv+Rf0HiWYrs/cSlOCwVOSRld9yz+mF7gAaLfAdwJWjdH3h8DftFA7/HlIVX0CoKo+XlUHt2MW8H9GOSdt3y9V1TPpBbsbgQ+PU/PufTU+CNit1Q5wPrBvkr2B5wIfG+c4/ef/GnAm8Hd91/bREde2bVUtAm4FHp7kIaPVNMKP277b97U9mrG/U0lTgMFTktbt48BLk8xNMoveLfkrqmpl2/4T4Lf79v8w8IokT0nPtknmJ9k+yeOTHN6Ocw9wN73b78PHGWqhkSSPTPK8FnTvBe7q23c0T0ry/DYr+Betz38AVNU9wKfatVxZVT/YgOs/DXhmkrn0nhf9gyS/n2RGkq2THJZkt6r6Pr3b7qckeXCSA4E/GO2AVfVD4HLg1HaMfYGXsZ6BWNLkZPCUpHWoqouBtwHn0ZvVeyxwfN8upwBntVvPL6yqJfSe83w/cAe9F3NOavvOAhYBP6V3K/kR9N5mh96LQQD/leRqev8b/Xp6s4OrgUOBPx+n1M/SuzV/B71nJZ/fnvccdhawD+vxUlG/qrodOBt4WwuMR7Wab6c3A/pG7v/35ATgQHqPIrwLOJdeAB7NAmCoXd9ngHe0Z0YlTVGp+o07O5KkKai9/HMj8FtV9d8dnfNc4Maqesc6d5Y05TnjKUnTQLt9/7+AczZn6Eyyf5LHJnlQ+92kR9F7vlSS8O1ASZri2jOiP6H31viRm/l0vwV8mt7LVz8C/qyqrhm/i6TpwlvtkiRJ6oS32iVJktQJg6ckSZI64TOeA7TzzjvX0NDQoMuQJElap6VLl/60qnbZmGMYPAdoaGiIJUuWDLoMSZKkdUry/XXvNT5vtUuSJKkTBk9JkiR1wuApSZKkThg8JUmS1AmDpyRJkjph8JQkSVInDJ6SJEnqhMFTkiRJnfAXyA/QilVrGDr5wkGXMWErF80fdAmSJGkSccZTkiRJnTB4SpIkqRMGT0mSJHXC4ClJkqROGDwlSZLUiXUGzyS/leScJN9NckOSLyR53EROluSkJI+aQL9TkrxhnO3Lk3xiIjVtQA2nJ9lrc55DkiRpKhs3eCYJ8Bngkqp6bFXtBbwFeOQEz3cSMGrwTDJjIgdM8rv0ruOQJNtOsK51nWNGVf1JVd2wOY4vSZI0HaxrxvPpwC+r6oPDDVW1rKq+DpDkjUmuSnJtkne2tqEk30ry4STXJ7koyTZJjgPmAR9Lsqy1rUzy9iSXAS9I8vJ2vOVJzkvykPW4hhcDHwUuAp433JjkkiT/mOTSVs/+ST6d5NtJ3tW33x8mubLV9KHhAJzkriR/leQK4MB2vHlt25FJrm51Xtzanpzk8iTXtJ+PX4/aJUmSpo11Bc+9gaWjbUjyLGAO8GRgLvCkJIe0zXOAD1TV7wE/A46tqk8BS4ATqmpuVd3d9r2nqg6uqnOAT1fV/lW1H/At4GXrcQ0vAs4FPgEsGLHtf6rqEOCDwGeBV7ZrOinJTm229EXAQVU1F1gLnND6bgtcV1VPqarL+q57F+DD7Zr2A17QNt0IHFJVTwDeDrx7jO9tYZIlSZas/cWa9bg8SZKkqWFj/nLRs9rnmra+Hb3A+QPglqpa1tqXAkPjHOfcvuW922zkQ9vxvjReAUn2B26vqu8n+RFwRpKHVdUdbZcL2s8VwPVVdWvr9z1gd+Bg4EnAVb2nCtgGuK31WQucN8ppDwAurapbAKpqdWvfETgryRyggK1Gq7mqFgOLAWbNnlPjXZ8kSdJUsq7geT1w3BjbApxaVR96QGMyBNzb17SWXqAby8/7ls8Ejq6q5UlOAg5bR30LgD2TrGzrOwDHAqe39eE67htR0330rj3AWVX15lGOfU9VrR2lPfSC5Uh/DXy1qo5p38El66hdkiRpWlnXrfavALOSvHy4oT0reSi92cg/TrJda981ySPWcbw7ge3H2b49cGuSrbj/lveokjyI3m3ufatqqKqGgKP4zdvt47kYOG647iQPT7LHOvp8Ezg0yWOG+7T2HYFVbfmkDahBkiRpWhg3eFZVAccAz2y/Tul64BTgx1V1EfBx4JtJVgCfYvxQCb0ZzQ8Ov1w0yva3AVcAX6b3zOR4DgFWVdWqvrZLgb2SzF5HXwDaW+r/G7goybXtvOP2rarbgYXAp5Ms5/5HBd4DnJrkG8CE3tCXJEmaytLLlhqEWbPn1OwTTxt0GRO2ctH8QZcgSZI6kmRpVc3bmGP4l4skSZLUCYOnJEmSOmHwlCRJUicMnpIkSerExvwCeW2kfXbdkSW+oCNJkqYJZzwlSZLUCYOnJEmSOmHwlCRJUicMnpIkSeqEwVOSJEmdMHhKkiSpEwZPSZIkdcLgKUmSpE4YPCVJktQJg6ckSZI6YfCUJElSJwyekiRJ6oTBU5IkSZ0weEqSJKkTBk9JkiR1wuApSZKkThg8JUmS1AmDpyRJkjph8JQkSVInZg66gOlsxao1DJ184aDL2CxWLpo/6BIkSdIWxhlPSZIkdcLgKUmSpE4YPCVJktQJg6ckSZI6sUmCZ5JK8vd9629IcsoGHuOwJE/tWz8zyXHr2feYVsOeG3LODaxvXpL3ba7jS5IkTXWbasbzXuD5SXaeSOckM4HDgKeuY9exLAAuA46fYP9xJZlZVUuq6jWb4/iSJEnTwaYKnr8CFgOvG7khyR5JLk5ybfv56NZ+ZpJ/SPJV4FzgFcDrkixL8rTW/ZAklyf53lizn0m2Aw4CXkZf8GwzqF9L8skkNydZlOSEJFcmWZHksW2/XZKcl+Sq9jmotZ+SZHGSi4Cz2/E+P3zOJB9px7k2ybGt/Z+TLElyfZJ3boovVpIkaarYlM94fgA4IcmOI9rfD5xdVfsCHwP6b1c/Djiiqo4FPgj8Y1XNraqvt+2zgYOB5wKLxjjv0cAXq+pmYHWSJ/Zt2w94LbAP8BLgcVX1ZOB04NVtn/e28+4PHNu2DXsScFRVvXjEOd8GrKmqfdp1faW1v7Wq5gH7Aocm2XeMmiVJkqadTfYL5Kvqv5OcDbwGuLtv04HA89vyR4H39G37t6paO85hz6+q+4AbkjxyjH0WAKe15XPa+tVt/aqquhUgyXeBi1r7CuDpbfkIYK8kw8fbIcn2bfmCquq/Fvr6/Hp2taruaIsvTLKQ3vc6G9gLuLa/Y9u+EGDGDruMcUmSJElTz6b+y0Wn0Qt9Hxlnn+pb/vk6jndv33JGbkyyE3A4sHeSAmYAleRNo/S/r2/9Pu6/9gcBB44MmC2IjlVfRlwHSR4DvAHYv6ruSHImsPXIjlW1mN5jCcyaPadGbpckSZqqNumvU6qq1cAn6T1vOexy7p8dPIHeS0CjuRPYfoxtYzmO3m38PapqqKp2B26hd3t+fV0EvGp4JcncCfR5GLADvaC6ps3OPnsDapAkSZryNsfv8fx7oP/t9tcAL01yLb3nLF87Rr/PAceMeLloXRYAnxnRdh4w8pnM8bwGmNdeErqB3ktO6/Iu4GFJrkuyHHh6VS0HrgGuB84AvrEBNUiSJE15qfJu76DMmj2nZp942qDL2CxWLpo/6BIkSdImlGRpe4l6wvzLRZIkSeqEwVOSJEmdMHhKkiSpEwZPSZIkdcLgKUmSpE5s6l8grw2wz647ssS3vyVJ0jThjKckSZI6YfCUJElSJwyekiRJ6oTBU5IkSZ0weEqSJKkTBk9JkiR1wuApSZKkThg8JUmS1AmDpyRJkjph8JQkSVInDJ6SJEnqhMFTkiRJnTB4SpIkqRMGT0mSJHXC4ClJkqROGDwlSZLUCYOnJEmSOmHwlCRJUidmDrqA6WzFqjUMnXzhoMvQZrJy0fxBlyBJ0hbFGU9JkiR1wuApSZKkThg8JUmS1AmDpyRJkjph8JQkSVInpl3wTFJJPtq3PjPJ7Uk+39ZPauvL+j57JRlqfV/d1/f9SU4acayfJjm104uSJEmaBKZd8AR+DuydZJu2/kxg1Yh9zq2quX2fG1r7bcBrkzx4jGM/C7gJeGGSbPLKJUmSJrHpGDwB/h0Y/iWLC4BPrGe/24GLgRPH2L4AeC/wA+CAjSlQkiRpqpmuwfMc4PgkWwP7AleM2P6iEbfat+nbtgh4fZIZ/R3aPs8APk8vyC7YfOVLkiRNPtMyeFbVtcAQvXD4hVF2GXmr/e6+vrcAVwIvHtHnucBXq+oXwHnAMSPDKUCShUmWJFmy9hdrNtEVSZIkbfmmZfBsLgD+jvW/zd7v3cBf8sDvbwFwRJKVwFJgJ+DpIztW1eKqmldV82Y8ZMcJnFqSJGlyms7B8wzgr6pqxYZ2rKobgRvozXKSZAfgYODRVTVUVUPAK/F2uyRJ0q9N2+BZVT+qqveOsXnkM55PHWWfvwF2a8vPB75SVff2bf8s8LwkszZh2ZIkSZPWzEEX0LWq2m6UtkuAS9rymcCZY3Tfu6/Pch4Y3B/Qp6pWA7tsRKmSJElTyrSd8ZQkSVK3DJ6SJEnqhMFTkiRJnTB4SpIkqRMGT0mSJHVi2r3VviXZZ9cdWbJo/rp3lCRJmgKc8ZQkSVInDJ6SJEnqhMFTkiRJnTB4SpIkqRMGT0mSJHXC4ClJkqROGDwlSZLUCYOnJEmSOmHwlCRJUicMnpIkSeqEwVOSJEmdMHhKkiSpEwZPSZIkdcLgKUmSpE4YPCVJktQJg6ckSZI6YfCUJElSJwyekiRJ6sTMQRcwna1YtYahky8cdBnSBlu5aP6gS5AkTULOeEqSJKkTBk9JkiR1wuApSZKkThg8JUmS1AmDpyRJkjqx0cEzyVuTXJ/k2iTLkjxlgsc5LMlT+9bPTHLcevY9Jkkl2XMi517Pc8xL8r7NdXxJkqSpbqN+nVKSA4HnAk+sqnuT7Aw8eIKHOwy4C7h8An0XAJcBxwOnTPD8Y0oys6qWAEs29bElSZKmi42d8ZwN/LSq7gWoqp9W1Y8BkjwjyTVJViQ5I8ms1r6yBdThWcRLkgwBrwBe12ZNn9aOf0iSy5N8b6zZzyTbAQcBL6MXPIfbD0vytSSfTHJzkkVJTkhyZavpsW2/XZKcl+Sq9jmotZ+SZHGSi4Cz2/E+P3zOJB9px7k2ybGt/Z+TLGkzwO/cyO9WkiRpStnY4HkRsHsLdv+U5FCAJFsDZwIvqqp96M2s/tlYB6mqlcAHgX+sqrlV9fW2aTZwML1Z1UVjdD8a+GJV3QysTvLEvm37Aa8F9gFeAjyuqp4MnA68uu3z3nbe/YFj27ZhTwKOqqoXjzjn24A1VbVPVe0LfKW1v7Wq5gH7Aocm2Xesa5YkSZpuNip4VtVd9MLZQuB24NwkJwGPB25pYRDgLOCQCZzi/Kq6r6puAB45xj4LgHPa8jltfdhVVXVrm5H9Lr2gDLACGGrLRwDvT7IMuADYIcn2bdsFVXX3KOc8AvjA8EpV3dEWX5jkauAa4PeAvUZ2TLKwzYouWfuLNWNckiRJ0tSz0X8ys6rWApcAlyRZAZwILBuny6+4P/BuvY7D39u3nJEbk+wEHA7snaSAGUAledMo/e/rW7+P+6/9QcCBIwNmEoCfj1FXgBqx/2OANwD7V9UdSc5klOurqsXAYoBZs+fUyO2SJElT1UbNeCZ5fJI5fU1zge8DNwJDSX6ntb8E+FpbXklvlhR6t7aH3Qlsz4Y5Dji7qvaoqqGq2h24hd7t+fV1EfCq4ZUkcyfQ52HADvSC6pokjwSevQE1SJIkTXkb+4zndsBZSW5Ici29W8unVNU9wEuBf2uzoPfRe4YT4J3Ae5N8HVjbd6zPAceMeLloXRYAnxnRdh4w8pnM8bwGmNdeErqB3ktO6/Iu4GFJrkuyHHh6VS2nd4v9euAM4BsbUIMkSdKUlyrv9g7KrNlzavaJpw26DGmDrVw0f9AlSJI6lmRpe4l6wvzLRZIkSeqEwVOSJEmdMHhKkiSpEwZPSZIkdcLgKUmSpE5s9C+Q18Tts+uOLPHtYEmSNE044ylJkqROGDwlSZLUCYOnJEmSOmHwlCRJUicMnpIkSeqEwVOSJEmdMHhKkiSpEwZPSZIkdcLgKUmSpE4YPCVJktQJg6ckSZI6YfCUJElSJwyekiRJ6oTBU5IkSZ0weEqSJKkTBk9JkiR1wuApSZKkThg8JUmS1ImZgy5gOluxag1DJ1846DIkqXMrF80fdAmSBsAZT0mSJHXC4ClJkqROGDwlSZLUCYOnJEmSOmHwlCRJUicMnqNIckySSrLnOvb7QpKHdlSWJEnSpGbwHN0C4DLg+PF2qqrnVNXPOqlIkiRpkjN4jpBkO+Ag4GW04JlkdpJLkyxLcl2Sp7X2lUl2bsvnJ1ma5PokCwd2AZIkSVsof4H8bzoa+GJV3ZxkdZInAk8HvlRVf5NkBvCQUfr9cVWtTrINcFWS86rqvzqsW5IkaYtm8PxNC4DT2vI5bf1zwBlJtgLOr6plo/R7TZJj2vLuwBzgN4Jnmw1dCDBjh102aeGSJElbMoNnnyQ7AYcDeycpYAZQwJuAQ4D5wEeT/G1Vnd3X7zDgCODAqvpFkkuArUc7R1UtBhYDzJo9pzbbxUiSJG1hfMbzgY4Dzq6qPapqqKp2B26hFzpvq6oPA/8CPHFEvx2BO1ro3BM4oNOqJUmSJgFnPB9oAbBoRNt5wJnAz5P8ErgL+KMR+3wReEWSa4GbgP/YzHVKkiRNOgbPPlV12Cht7wPeN8b+Q32rz948VUmSJE0N3mqXJElSJwyekiRJ6oTBU5IkSZ0weEqSJKkTvlw0QPvsuiNLFs0fdBmSJEmdcMZTkiRJnTB4SpIkqRMGT0mSJHXC4ClJkqROGDwlSZLUCYOnJEmSOmHwlCRJUicMnpIkSeqEwVOSJEmdMHhKkiSpEwZPSZIkdcLgKUmSpE4YPCVJktQJg6ckSZI6YfCUJElSJwyekiRJ6oTBU5IkSZ0weEqSJKkTBk9JkiR1YuagC5jOVqxaw9DJFw66DEmadFYumj/oEiRNgDOekiRJ6oTBU5IkSZ0weEqSJKkTBk9JkiR1wuApSZKkTkzL4JnkmCSVZM+2vkuSK5Jck+Rpo+x/epK9uq9UkiRp6piWwRNYAFwGHN/WnwHcWFVPqKqv9++YZEZV/UlV3dB1kZIkSVPJtAueSbYDDgJeBhyfZC7wHuA5SZYl2SbJXUn+KskVwIFJLkkyr/U/MsnVSZYnubi1PTnJ5W3G9PIkjx/Q5UmSJG2xpuMvkD8a+GJV3ZxkNb3w/XZgXlW9CiDJtsB1VfX2tk77uQvwYeCQqrolycPbMW9sbb9KcgTwbuDYDq9JkiRpizcdg+cC4LS2fE5bv37EPmuB80bpewBwaVXdAlBVq1v7jsBZSeYABWw11smTLAQWAszYYZeJXYEkSdIkNK2CZ5KdgMOBvZMUMINeUHzHiF3vqaq1ox2i7T/SXwNfrapjkgwBl4xVQ1UtBhYDzJo9Z7RjSZIkTUnT7RnP44Czq2qPqhqqqt2BW4Dd1rP/N4FDkzwGoO9W+47AqrZ80iasV5IkacqYbsFzAfCZEW3nAW9Zn85VdTu92+SfTrIcOLdteg9wapJv0JtFlSRJ0gip8m7voMyaPadmn3jaoMuQpEln5aL5gy5BmnaSLK2qeRtzjOk24ylJkqQBMXhKkiSpEwZPSZIkdcLgKUmSpE5Mq9/juaXZZ9cdWeID8pIkaZpwxlOSJEmdMHhKkiSpEwZPSZIkdcLgKUmSpE4YPCVJktQJg6ckSZI6YfCUJElSJwyekiRJ6oTBU5IkSZ0weEqSJKkTBk9JkiR1wuApSZKkThg8JUmS1AmDpyRJkjph8JQkSVInDJ6SJEnqhMFTkiRJnTB4SpIkqRMGT0mSJHVi5qALmM5WrFrD0MkXDroMSZI0Sa1cNH/QJWwQZzwlSZLUCYOnJEmSOmHwlCRJUicMnpIkSeqEwVOSJEmdmLJvtSdZC6zoazqnqhYNqh5JkqTpbsoGT+Duqpo7kY5JZlbVrzZxPZIkSdPatLvVnmRlkp3b8rwkl7TlU5IsTnIRcHaSPZJcnOTa9vPRbb8zk3wwydeT3Jzkua19RpK/TXJV6/Ong7pGSZKkLdFUnvHcJsmyvvVTq+rcdfR5EnBwVd2d5HPA2VV1VpI/Bt4HHN32GwIOBR4LfDXJ7wB/BKypqv2TzAK+keSiqrql/wRJFgILAWbssMtGXaAkSdJkMpWD50RutV9QVXe35QOB57fljwLv6dvvk1V1H/DtJN8D9gSeBeyb5Li2z47AHOABwbOqFgOLAWbNnlMbWJ8kSdKkNZWD51h+xf2PGGw9YtvPx+lXYywPrwd4dVV9aePKkyRJmpqm3TOewEp6t9QBjh1nv8uB49vyCcBlfdtekORBSR4L/DZwE/Al4M+SbAWQ5HFJtt2UhUuSJE1mU3nGc+Qznl+sqpOBdwL/kuQtwBXj9H8NcEaSNwK3Ay/t23YT8DXgkcArquqeJKfTe/bz6iRpfY7eRNciSZI06U3Z4FlVM8Zo/zrwuFHaTxmxvhI4fIzDf6OqXjdi//uAt7SPJEmSRpiOt9olSZI0AFN2xnNzqaqTBl2DJEnSZOSMpyRJkjph8JQkSVInvNU+QPvsuiNLFs0fdBmSJEmdcMZTkiRJnTB4SpIkqRMGT0mSJHXC4ClJkqROGDwlSZLUCYOnJEmSOmHwlCRJUicMnpIkSeqEwVOSJEmdSFUNuoZpK8mdwE2DrkMTsjPw00EXoQlx7CYvx27ycuwmr/6x26OqdtmYg/knMwfrpqqaN+gitOGSLHHsJifHbvJy7CYvx27y2tRj5612SZIkdcLgKUmSpE4YPAdr8aAL0IQ5dpOXYzd5OXaTl2M3eW3SsfPlIkmSJHXCGU9JkiR1wuA5AEmOTHJTku8kOXnQ9QiSnJHktiTX9bU9PMmXk3y7/XxY37Y3t/G7Kcnv97U/KcmKtu19SdL1tUw3SXZP8tUk30pyfZLXtnbHbwuXZOskVyZZ3sbuna3dsZskksxIck2Sz7d1x24SSLKyfefLkixpbZ2MncGzY0lmAB8Ang3sBSxIstdgqxJwJnDkiLaTgYurag5wcVunjdfxwO+1Pv/UxhXgn4GFwJz2GXlMbXq/Al5fVb8LHAC8so2R47fluxc4vKr2A+YCRyY5AMduMnkt8K2+dcdu8nh6Vc3t+1VJnYydwbN7Twa+U1Xfq6r/Ac4BjhpwTdNeVV0KrB7RfBRwVls+Czi6r/2cqrq3qm4BvgM8OclsYIeq+mb1Hp4+u6+PNpOqurWqrm7Ld9L7R3BXHL8tXvXc1Va3ap/CsZsUkuwGzAdO72t27CavTsbO4Nm9XYEf9q3/qLVpy/PIqroVeuEGeERrH2sMd23LI9vVkSRDwBOAK3D8JoV2q3YZcBvw5apy7CaP04A3Aff1tTl2k0MBFyVZmmRha+tk7PzLRd0b7fkHf7XA5DLWGDq2A5RkO+A84C+q6r/HedTI8duCVNVaYG6ShwKfSbL3OLs7dluIJM8FbquqpUkOW58uo7Q5doNzUFX9OMkjgC8nuXGcfTfp2Dnj2b0fAbv3re8G/HhAtWh8P2m3Emg/b2vtY43hj9ryyHZtZkm2ohc6P1ZVn27Njt8kUlU/Ay6h94yYY7flOwh4XpKV9B4ZOzzJv+LYTQpV9eP28zbgM/QeA+xk7Aye3bsKmJPkMUkeTO+B3QsGXJNGdwFwYls+EfhsX/vxSWYleQy9B6qvbLcm7kxyQHuz74/6+mgzad/1vwDfqqp/6Nvk+G3hkuzSZjpJsg1wBHAjjt0Wr6reXFW7VdUQvX/HvlJVf4hjt8VLsm2S7YeXgWcB19HV2FWVn44/wHOAm4HvAm8ddD1+CuATwK3AL+n9v7iXATvRe7Pv2+3nw/v2f2sbv5uAZ/e1z2v/AX8XeD/tjzT42axjdzC92zvXAsva5zmO35b/AfYFrmljdx3w9tbu2E2iD3AY8HnHbnJ8gN8GlrfP9cM5pKux8y8XSZIkqRPeapckSVInDJ6SJEnqhMFTkiRJnTB4SpIkqRMGT0mSJHXC4ClJkqROGDwlSZLUCYOnJEmSOvH/AQQ7bruz/HikAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['region'].value_counts().head(10).plot(kind='barh',figsize=(10 , 5),\n",
    "                                           title='Protests by Region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Modelling\n",
    "\n",
    "Objective:  Optimize the model selection through gridsearch. Then append dataframe results.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_responses = ['y_accomodation', 'y_arrests', 'y_beatings', 'y_crowd_dispersal', 'y_ignore', 'y_killings', 'y_shootings']\n",
    "\n",
    "region_list = dict(df[\"region\"].value_counts()).keys()\n",
    "\n",
    "country_list = dict(df[\"country\"].value_counts()).keys()\n",
    "\n",
    "all_features = ['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions', 'notes']\n",
    "\n",
    "num_features = ['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg__protest_by_the_response(df, response):    \n",
    "    X = df[all_features]\n",
    "    y = df[response]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[num_features], validate=False)\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('log', LogisticRegression(max_iter=5000))\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "        'log__penalty' : ['l2', 'l1'],\n",
    "#        'log__C' : [0.001, 0.01, 0,1, 1, 5],\n",
    "#        'features__text_features__cvec__max_df': [0.90, 0.95],\n",
    "#        'features__text_features__cvec__max_features': [None, 1000, 3000, 5000],\n",
    "        'log__solver' : ['liblinear']\n",
    "    }\n",
    "    \n",
    "\n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "    \n",
    "    reg_response_dict = {\n",
    "        \"model_type\": \"logreg\",\n",
    "        \"region\": df[\"region\"].iloc[0],\n",
    "        \"training_score\": gs.score(X_train, y_train),\n",
    "        \"testing_score\": gs.score(X_test, y_test),\n",
    "        \"baseline\": baseline,\n",
    "        \"baseline_response\": (response[2:] if df[response].mean() > 0.5 else f\"no {response[2:]}\"),\n",
    "        \"model_success\": (\"yes\" if gs.score(X_test, y_test) > (0.05+baseline) else \"no\"),\n",
    "        \"best_params\": gs.best_params_\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf__protest_by_the_response(df, response):\n",
    "    X = df[all_features]\n",
    "    y = df[response]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[num_features], validate=False)\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('rf', RandomForestClassifier())\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "#        'rf__ccp_alpha' : [0.001, 0.01, 0.1, 1, 5],\n",
    "        'rf__n_estimators' : [100, 300],\n",
    "        'rf__max_depth' : [None, 5, 10],\n",
    "        'rf__min_samples_split' : [2, 4],\n",
    "        'rf__min_samples_leaf' : [1, 3]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "            \n",
    "    reg_response_dict = {\n",
    "        \"model_type\": \"rf\",\n",
    "        \"region\": df[\"region\"].iloc[0],\n",
    "        \"training_score\": gs.score(X_train, y_train),\n",
    "        \"testing_score\": gs.score(X_test, y_test),\n",
    "        \"baseline\": baseline,\n",
    "        \"baseline_response\": (response[2:] if df[response].mean() > 0.5 else f\"no {response[2:]}\"),\n",
    "        \"model_success\": (\"yes\" if gs.score(X_test, y_test) > (0.05+baseline) else \"no\"),\n",
    "        \"best_params\": gs.best_params_\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc__protest_by_the_response(df, response):\n",
    "    X = df[all_features]\n",
    "    y = df[response]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[num_features], validate=False)\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('svc', SVC())\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "        'svc__C' : [5],\n",
    "        'svc__degree' :[2],\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "            \n",
    "    reg_response_dict = {\n",
    "        \"model_type\": \"svc\",\n",
    "        \"region\": df[\"region\"].iloc[0],\n",
    "        \"training_score\": gs.score(X_train, y_train),\n",
    "        \"testing_score\": gs.score(X_test, y_test),\n",
    "        \"baseline\": baseline,\n",
    "        \"baseline_response\": (response[2:] if df[response].mean() > 0.5 else f\"no {response[2:]}\"),\n",
    "        \"model_success\": (\"yes\" if gs.score(X_test, y_test) > (0.05+baseline) else \"no\"),\n",
    "        \"best_params\": gs.best_params_\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb__protest_by_the_response(df, response):\n",
    "    X = df[all_features]\n",
    "    y = df[response]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[num_features], validate=False)\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('xg', XGBClassifier())\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "#        'xg__gamma' : [0.001, 0.01, 0.1, 1, 5],\n",
    "        'xg__max_depth' :[None, 2, 3],\n",
    "#        'xg__learning_rate' : [0.001, 0.01, 0.1, 1, 5]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "            \n",
    "    reg_response_dict = {\n",
    "        \"model_type\": \"xgb\",\n",
    "        \"region\": df[\"region\"].iloc[0],\n",
    "        \"training_score\": gs.score(X_train, y_train),\n",
    "        \"testing_score\": gs.score(X_test, y_test),\n",
    "        \"baseline\": baseline,\n",
    "        \"baseline_response\": (response[2:] if df[response].mean() > 0.5 else f\"no {response[2:]}\"),\n",
    "        \"model_success\": (\"yes\" if gs.score(X_test, y_test) > (0.05+baseline) else \"no\"),\n",
    "        \"best_params\": gs.best_params_\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Remaining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results = pd.DataFrame(columns=[\"model_type\", \"region\", \"baseline_response\", \"training_score\", \"testing_score\", \"baseline\", \"model_success\", \"best_params\"])\n",
    "\n",
    "\n",
    "\n",
    "def logreg__responses_by_location(loc_df):\n",
    "    return [logreg__protest_by_the_response(loc_df, response) for response in possible_responses]\n",
    "\n",
    "def rf__responses_by_location(loc_df):\n",
    "    return [rf__protest_by_the_response(loc_df, response) for response in possible_responses]\n",
    "\n",
    "def svc__responses_by_location(loc_df):\n",
    "    return [svc__protest_by_the_response(loc_df, response) for response in possible_responses]\n",
    "\n",
    "def xgb__responses_by_location(loc_df):\n",
    "    return [xgb__protest_by_the_response(loc_df, response) for response in possible_responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_by_region(df, region):\n",
    "    return df[df[\"region\"]==region]\n",
    "\n",
    "def df_by_country(df, country):\n",
    "    return df[df[\"country\"]==country]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Running the models\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Burger\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "for region in region_list:\n",
    "    for dct in logreg__responses_by_location(df_by_region(df, region)):\n",
    "        grid_results = grid_results.append(dct, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e414541d87d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mregion\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mregion_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdct\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrf__responses_by_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_by_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mgrid_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-4749b68c06b1>\u001b[0m in \u001b[0;36mrf__responses_by_location\u001b[1;34m(loc_df)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrf__responses_by_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrf__protest_by_the_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossible_responses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msvc__responses_by_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-4749b68c06b1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrf__responses_by_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrf__protest_by_the_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossible_responses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msvc__responses_by_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-cbde5ed7265a>\u001b[0m in \u001b[0;36mrf__protest_by_the_response\u001b[1;34m(df, response)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mbaseline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    387\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                                         indices=indices)\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \"\"\"\n\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for region in region_list:\n",
    "    for dct in rf__responses_by_location(df_by_region(df, region)):\n",
    "        grid_results = grid_results.append(dct, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in region_list:\n",
    "    for dct in svc__responses_by_location(df_by_region(df, region)):\n",
    "        grid_results = grid_results.append(dct, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in region_list:\n",
    "    for dct in xgb__responses_by_location(df_by_region(df, region)):\n",
    "        grid_results = grid_results.append(dct, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_results.to_csv(\"./data/four_models.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Engineering & Assessment\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results[\"success_rate\"] = grid_results[\"testing_score\"] - grid_results[\"baseline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = grid_results[grid_results[\"model_type\"] == \"logreg\"][\"success_rate\"].mean()\n",
    "rf = grid_results[grid_results[\"model_type\"] == \"rf\"][\"success_rate\"].mean()\n",
    "svc = grid_results[grid_results[\"model_type\"] == \"svc\"][\"success_rate\"].mean()\n",
    "xgb = grid_results[grid_results[\"model_type\"] == \"xgb\"][\"success_rate\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Logistic Regression:\\t{lg}\")\n",
    "print(f\"Random Forest:\\t\\t{rf}\")\n",
    "print(f\"SVC:\\t\\t\\t{svc}\")\n",
    "print(f\"XGB Classifier:\\t\\t{xgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Additional Modelling\n",
    "---\n",
    "---\n",
    "Consolidating the possible protest outcomes into broader, more predictable categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_drops = ['y_arrests', 'y_crowd_dispersal', 'y_beatings', 'y_killings', 'y_shootings']\n",
    "\n",
    "df[\"y_adverse_reaction\"] = df[\"y_arrests\"] + df[\"y_crowd_dispersal\"]\n",
    "df[\"y_adverse_reaction\"] = df[\"y_adverse_reaction\"].map(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "df[\"y_state_violence\"] = df[\"y_beatings\"] + df[\"y_killings\"] + df[\"y_shootings\"]\n",
    "df[\"y_state_violence\"] = df[\"y_state_violence\"].map(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "df.drop(columns=new_drops, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_responses = ['y_accomodation', 'y_ignore', 'y_adverse_reaction', 'y_state_violence']\n",
    "possible_demands = ['demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions']\n",
    "\n",
    "for r in possible_responses:\n",
    "    df[r] = df[r].map(lambda x: 1 if x>0 else 0)\n",
    "    \n",
    "for d in possible_demands:\n",
    "    df[d] = df[d].map(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_responses = ['y_accomodation', 'y_ignore', 'y_adverse_reaction', 'y_state_violence']\n",
    "\n",
    "def xgb__protest_by_the_response(df, response):\n",
    "    xgb_features = all_features + [\"country\", \"protesteridentity\", \"sources\"]\n",
    "    text_features = [\"country\", \"protesteridentity\", \"sources\", \"notes\"]\n",
    "    \n",
    "    X = df[xgb_features]\n",
    "    y = df[response]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[num_features], validate=False)\n",
    "    get_text_data = FunctionTransformer(lambda df: df[text_features], validate=False)\n",
    "    \n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('xg', XGBClassifier())\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "#        'xg__gamma' : [0.001, 0.01, 0.1, 1, 5],\n",
    "        'xg__max_depth' :[2],\n",
    "#        'xg__learning_rate' : [0.001, 0.01, 0.1, 1, 5]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "            \n",
    "    reg_response_dict = {\n",
    "        \"model_type\": \"xgb\",\n",
    "        \"region\": df[\"region\"].iloc[0],\n",
    "        \"training_score\": gs.score(X_train, y_train),\n",
    "        \"testing_score\": gs.score(X_test, y_test),\n",
    "        \"baseline\": baseline,\n",
    "        \"baseline_response\": (response[2:] if df[response].mean() > 0.5 else f\"no {response[2:]}\"),\n",
    "        \"model_success\": (\"yes\" if gs.score(X_test, y_test) > (0.05+baseline) else \"no\"),\n",
    "        \"best_params\": gs.best_params_\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb__protest_by_the_response(df, response):\n",
    "    X = df[all_features]\n",
    "    y = df[response]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[num_features], validate=False)\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('xg', XGBClassifier())\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "#        'xg__gamma' : [0.001, 0.01, 0.1, 1, 5],\n",
    "        'xg__max_depth' :[2],\n",
    "#        'xg__learning_rate' : [0.001, 0.01, 0.1, 1, 5]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "            \n",
    "    reg_response_dict = {\n",
    "        \"model_type\": \"xgb\",\n",
    "        \"region\": df[\"region\"].iloc[0],\n",
    "        \"training_score\": gs.score(X_train, y_train),\n",
    "        \"testing_score\": gs.score(X_test, y_test),\n",
    "        \"baseline\": baseline,\n",
    "        \"baseline_response\": (response[2:] if df[response].mean() > 0.5 else f\"no {response[2:]}\"),\n",
    "        \"model_success\": (\"yes\" if gs.score(X_test, y_test) > (0.05+baseline) else \"no\"),\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb__responses_by_location(loc_df):\n",
    "    return [xgb__protest_by_the_response(loc_df, response) for response in possible_responses]\n",
    "\n",
    "def df_by_region(df, region):\n",
    "    return df[df[\"region\"]==region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results = pd.DataFrame(columns=[\"model_type\", \"region\", \"baseline_response\", \"training_score\", \"testing_score\", \"baseline\", \"model_success\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for region in region_list:\n",
    "    for dct in xgb__responses_by_location(df_by_region(df, region)):\n",
    "        xgb_results = xgb_results.append(dct, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results[\"success_rate\"] = xgb_results[\"testing_score\"] - xgb_results[\"baseline\"]\n",
    "\n",
    "xgb_success = xgb_results[xgb_results[\"baseline\"]<0.85][\"success_rate\"].mean()\n",
    "print(f\"XGB Success Rate for baselines under 85%:\\t{xgb_success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0f18acc368d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'o'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot('x', 'y', data=df, marker='o', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
