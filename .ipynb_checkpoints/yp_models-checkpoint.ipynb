{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial imports and declarations\n",
    "Will be expanded later to include a bevy of imports for various processing, data exploration, and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "\n",
    "#models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "#post-modelling metrics\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"protests.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Structures \n",
    "Includes function declarations, lists, dictionaries, etc. that are used later in the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_drops = [\n",
    "    '1_accomodation', '1_arrests', '1_beatings', '1_crowd dispersal', '1_ignore', '1_killings', '1_shootings',\n",
    "    '2_accomodation', '2_arrests', '2_beatings', '2_crowd dispersal', '2_ignore', '2_killings', '2_shootings', \n",
    "    '3_accomodation', '3_arrests', '3_beatings', '3_crowd dispersal', '3_ignore', '3_killings', '3_shootings', \n",
    "    '4_accomodation', '4_arrests', '4_beatings', '4_crowd dispersal', '4_killings', '4_shootings', \n",
    "    '5_.', '5_accomodation', '5_arrests', '5_beatings', '5_crowd dispersal', '5_killings', '5_shootings', \n",
    "    '6_accomodation', '6_arrests', '6_beatings', '6_crowd dispersal', '6_killings', \n",
    "    '7_.', '7_accomodation', '7_arrests', '7_beatings', '7_killings'\n",
    "]\n",
    "\n",
    "demand_drops = [\n",
    "    'demand1_labor wage dispute', 'demand1_land farm issue', 'demand1_police brutality', 'demand1_political behavior, process', 'demand1_price increases, tax policy', 'demand1_removal of politician', 'demand1_social restrictions', \n",
    "    'demand2_labor wage dispute', 'demand2_land farm issue', 'demand2_police brutality', 'demand2_political behavior, process', 'demand2_price increases, tax policy', 'demand2_removal of politician', 'demand2_social restrictions', \n",
    "    'demand3_labor wage dispute', 'demand3_land farm issue', 'demand3_police brutality', 'demand3_political behavior, process', 'demand3_price increases, tax policy', 'demand3_removal of politician', 'demand3_social restrictions', \n",
    "    'demand4_.', 'demand4_labor wage dispute', 'demand4_land farm issue', 'demand4_police brutality', 'demand4_political behavior, process', 'demand4_price increases, tax policy', 'demand4_removal of politician'\n",
    "]\n",
    "\n",
    "time_drops = ['startday', 'startmonth', 'startyear', 'endday', 'endmonth', 'endyear']\n",
    "\n",
    "other_drops = [\n",
    "    'id', #Not useful to prediction.\n",
    "    'ccode', #Not useful to prediction.\n",
    "    'protest', #All values are 1.  Is this dataset the subset of another?\n",
    "    'protestnumber', # of protests per country might be useful but not in the context of incremental numbers that it's being given\n",
    "    'location', #Not extremely useable given how it's already being broken by region.\n",
    "    'participants_category', #Too many null values to be of great value.\n",
    "]\n",
    "\n",
    "demands = ['protesterdemand1', 'protesterdemand2', 'protesterdemand3', 'protesterdemand4']\n",
    "\n",
    "response = [\"stateresponse1\", \"stateresponse2\", \"stateresponse3\", \"stateresponse4\", \"stateresponse5\", \"stateresponse6\", \"stateresponse7\"]\n",
    "\n",
    "targets = ['y_accomodation', 'y_arrests', 'y_beatings', 'y_crowd dispersal', 'y_ignore', 'y_killings', 'y_shootings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_texts(x):\n",
    "    x = x.lower()\n",
    "    \n",
    "    if x == \"dozens\":\n",
    "        return 50\n",
    "    elif x == \"hundreds\":\n",
    "        return 500\n",
    "    elif x == \"thousands\":\n",
    "        return 5000\n",
    "    elif x == \"tens of thousands\":\n",
    "        return 50000\n",
    "    elif \"hundreds of thousands\" in x:\n",
    "        return 250000\n",
    "    elif \"millions\" in x:\n",
    "        return 2000000\n",
    "    elif \"million\" in x:\n",
    "        return 1000000\n",
    "    \n",
    "    \n",
    "    elif \"about \" in x:\n",
    "        return x[6:]\n",
    "    elif \"more than \" in x:\n",
    "        return x[10:]\n",
    "    \n",
    "    \n",
    "    elif \"several\" in x:\n",
    "        if \"dozen\" in x:\n",
    "            return 50\n",
    "        elif \"hundred\" in x:\n",
    "            return 500\n",
    "        elif \"thousand\" in x:\n",
    "            return 5000\n",
    "    \n",
    "    \n",
    "    elif \"hundreds\" in x:\n",
    "        return 500\n",
    "    elif \"thousands\" in x:\n",
    "        return 5000\n",
    "    \n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def strip_chars(x):\n",
    "    banned_chars = \"+s><,\"\n",
    "    x = \"\".join([c for c in x if c not in banned_chars])\n",
    "    \n",
    "    try:\n",
    "        x = int(x)\n",
    "    finally:\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "def avg_hyphen(x):\n",
    "    accepted_chars = \"1234567890-\"\n",
    "    ind = 0\n",
    "\n",
    "    x = \"\".join([c for c in x if c in accepted_chars])\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        if x[i] == \"-\":\n",
    "            ind = i\n",
    "    \n",
    "    lower = x[:ind]\n",
    "    upper = x[ind+1:]\n",
    "    \n",
    "    if (lower == \"\") or (upper==\"\"):\n",
    "        return np.nan\n",
    "    \n",
    "    return (int(lower) + int(upper)) /2\n",
    "    \n",
    "    \n",
    "    \n",
    "def map_participants(x):\n",
    "    while type(x) == str:\n",
    "        x = parse_texts(x)\n",
    "        if type(x) == str:\n",
    "            x = strip_chars(x)\n",
    "        if type(x) == str:\n",
    "            x = avg_hyphen(x)\n",
    "        if type(x) == str:\n",
    "            x = np.nan\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Cleaning\n",
    "Contains blocks of code for known cleaning problems derived from any previous data exploration.\n",
    "\n",
    "To-do:\n",
    "1. Dummify and verticalize protestor demands.\n",
    "2. Rectify the participants_category, participants columns\n",
    "3. Get \"protest length\" as a feature\n",
    "4. drop id, ccode, protestnumber(?), sources(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General/Miscellaneous Cleaning\n",
    "\n",
    "df.dropna(subset=[\"notes\"], inplace=True) #If there are no notes, then we will not be able to predict the outcome very well.\n",
    "df.dropna(subset=[\"participants\"], inplace=True) #Participants had very few NaN values\n",
    "df.dropna(subset=[\"sources\"], inplace=True) #Sources had very few NaN values\n",
    "\n",
    "\n",
    "#Miscellaneous useless feature cleaning.  See the list declaration [other_drops] in DATA STRUCTURES for additional information.\n",
    "df.drop(columns=other_drops, inplace=True)\n",
    "\n",
    "\n",
    "#For the 500 or so values containing NaN in protestor identity:\n",
    "df.fillna(value={\"protesteridentity\":\"unspecified\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#For fixing the time values such that a length of time (in days) for the protest is established as a feature, and other time features are dropped.\n",
    "#Critically, the year the protest initially occured is retained in another column.\n",
    "\n",
    "month_days = {1:0, 2:31, 3:59, 4:90, 5:120, 6:151, 7:181, 8:212, 9:243, 10:273, 11:304, 12:334}\n",
    "df[\"protest_length\"] = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    yearday_start = month_days[df[\"startmonth\"].iloc[i]] + df[\"startday\"].iloc[i]\n",
    "    yearday_end = month_days[df[\"endmonth\"].iloc[i]] + df[\"endday\"].iloc[i]\n",
    "    \n",
    "    difference = (yearday_end - yearday_start) + (365 * (df[\"endyear\"].iloc[i] - df[\"startyear\"].iloc[i]))\n",
    "    \n",
    "    if difference != 0:\n",
    "        df[\"protest_length\"].iloc[i] = difference\n",
    "    else:\n",
    "        df[\"protest_length\"].iloc[i] = 1 #accounts for same-day protests\n",
    "\n",
    "\n",
    "#Now that the length is obtained, the additional time columns can be dropped.\n",
    "df.drop(columns=time_drops, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For fixing the Participants feature such that we have a numerical value.\n",
    "#For more information, see the function map_participants() in DATA STRUCTURES.\n",
    "df[\"participants\"] = df[\"participants\"].map(map_participants)\n",
    "\n",
    "df.dropna(subset=[\"participants\"], inplace=True) #150 null values remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For translating the vertical state response & the protester demands values laterally.\n",
    "\n",
    "\n",
    "df = pd.get_dummies(data=df, prefix=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], columns=response)\n",
    "df = pd.get_dummies(data=df, prefix=[\"demand1\", \"demand2\", \"demand3\", \"demand4\"], columns=demands)\n",
    "\n",
    "\n",
    "#Combining the disparate dummies into unified response columns.  \n",
    "#Unfortunately there was a certain amount of manual labor involved in this due to how finicky pandas is.\n",
    "df[\"demand_labor_wage_dispute\"] = df['demand1_labor wage dispute'] + df['demand2_labor wage dispute'] + df['demand3_labor wage dispute'] + df['demand4_labor wage dispute']\n",
    "df[\"demand_land_farm_issue\"] = df['demand1_land farm issue'] + df['demand2_land farm issue'] + df['demand3_land farm issue'] + df['demand4_land farm issue']\n",
    "df[\"demand_police_brutality\"] = df['demand1_police brutality'] + df['demand2_police brutality'] + df['demand3_police brutality'] + df['demand4_police brutality']\n",
    "df[\"demand_political_behavior_or_process\"] = df['demand1_political behavior, process'] + df['demand2_political behavior, process'] + df['demand3_political behavior, process'] + df['demand4_political behavior, process']\n",
    "df[\"demand_price_hike_or_tax_policy\"] = df['demand1_price increases, tax policy'] + df['demand2_price increases, tax policy'] + df['demand3_price increases, tax policy'] + df['demand4_price increases, tax policy']\n",
    "df[\"demand_removal_of_politician\"] = df['demand1_removal of politician'] + df['demand2_removal of politician'] + df['demand3_removal of politician'] + df['demand4_removal of politician']\n",
    "df[\"demand_social_restrictions\"] = df['demand1_social restrictions'] + df['demand2_social restrictions'] + df['demand3_social restrictions']\n",
    "\n",
    "df[\"y_accomodation\"] = df['1_accomodation'] + df['2_accomodation'] + df['3_accomodation'] + df['4_accomodation'] + df['5_accomodation'] + df['6_accomodation'] + df['7_accomodation']\n",
    "df[\"y_arrests\"] = df['1_arrests'] + df['2_arrests'] + df['3_arrests'] + df['4_arrests'] + df['5_arrests'] + df['6_arrests'] + df['7_arrests']\n",
    "df[\"y_beatings\"] = df['1_beatings'] + df['2_beatings'] + df['3_beatings'] + df['4_beatings'] + df['5_beatings'] + df['6_beatings'] + df['7_beatings']\n",
    "df[\"y_crowd_dispersal\"] = df['1_crowd dispersal'] + df['2_crowd dispersal'] + df['3_crowd dispersal'] + df['4_crowd dispersal'] + df['5_crowd dispersal'] + df['6_crowd dispersal']\n",
    "df[\"y_ignore\"] = df['1_ignore'] + df['2_ignore'] + df['3_ignore']\n",
    "df[\"y_killings\"] = df['1_killings'] + df['2_killings'] + df['3_killings'] + df['4_killings'] + df['5_killings'] + df['6_killings'] + df['7_killings']\n",
    "df[\"y_shootings\"] = df['1_shootings'] + df['2_shootings'] + df['3_shootings'] + df['4_shootings'] + df['5_shootings']\n",
    "\n",
    "\n",
    "\n",
    "#Getting rid of the disparate dummies now that we have unified responses.\n",
    "#Dropping Oceania since not relevant/out of scope\n",
    "\n",
    "df.drop(columns=response_drops, inplace=True)\n",
    "df.drop(columns=demand_drops, inplace=True)\n",
    "df = df[df['region']!='Oceania']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data exploration & analysis\n",
    "Find problems to address here and then address them in the data cleaning section.  Or, create graphs or other data exploration methods here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United Kingdom           543\n",
       "France                   527\n",
       "Ireland                  428\n",
       "Germany                  360\n",
       "Kenya                    348\n",
       "                        ... \n",
       "Serbia and Montenegro      2\n",
       "Cape Verde                 2\n",
       "Laos                       2\n",
       "South Sudan                1\n",
       "Qatar                      1\n",
       "Name: country, Length: 165, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"country\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'year', 'region', 'protesterviolence', 'participants',\n",
       "       'protesteridentity', 'sources', 'notes', 'protest_length',\n",
       "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
       "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
       "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
       "       'demand_social_restrictions', 'y_accomodation', 'y_arrests',\n",
       "       'y_beatings', 'y_crowd_dispersal', 'y_ignore', 'y_killings',\n",
       "       'y_shootings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14264 entries, 0 to 16312\n",
      "Data columns (total 23 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   country                               14264 non-null  object \n",
      " 1   year                                  14264 non-null  int64  \n",
      " 2   region                                14264 non-null  object \n",
      " 3   protesterviolence                     14264 non-null  float64\n",
      " 4   participants                          14264 non-null  float64\n",
      " 5   protesteridentity                     14264 non-null  object \n",
      " 6   sources                               14264 non-null  object \n",
      " 7   notes                                 14264 non-null  object \n",
      " 8   protest_length                        14264 non-null  float64\n",
      " 9   demand_labor_wage_dispute             14264 non-null  uint8  \n",
      " 10  demand_land_farm_issue                14264 non-null  uint8  \n",
      " 11  demand_police_brutality               14264 non-null  uint8  \n",
      " 12  demand_political_behavior_or_process  14264 non-null  uint8  \n",
      " 13  demand_price_hike_or_tax_policy       14264 non-null  uint8  \n",
      " 14  demand_removal_of_politician          14264 non-null  uint8  \n",
      " 15  demand_social_restrictions            14264 non-null  uint8  \n",
      " 16  y_accomodation                        14264 non-null  uint8  \n",
      " 17  y_arrests                             14264 non-null  uint8  \n",
      " 18  y_beatings                            14264 non-null  uint8  \n",
      " 19  y_crowd_dispersal                     14264 non-null  uint8  \n",
      " 20  y_ignore                              14264 non-null  uint8  \n",
      " 21  y_killings                            14264 non-null  uint8  \n",
      " 22  y_shootings                           14264 non-null  uint8  \n",
      "dtypes: float64(3), int64(1), object(5), uint8(14)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Models\n",
    "\n",
    "Three core objectives - \n",
    "1. FeatureUnion to run a model that takes in multiple data types (that will be nested in)\n",
    "2. Function that cycles through possible state responses (that will be nested in)\n",
    "3. Function that cycles through possible regions or countries for possible state responses\n",
    "4. And finally (4) which is permitting for time cut offs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X = df[['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions', 'notes']]\n",
    "\n",
    "    y = df['y_ignore']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions']], validate=False)\n",
    "\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('xg', XGBClassifier())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('features',\n",
       "   FeatureUnion(transformer_list=[('numeric_features',\n",
       "                                   Pipeline(steps=[('selector',\n",
       "                                                    FunctionTransformer(func=<function <lambda> at 0x7fe62923bd30>)),\n",
       "                                                   ('ss', StandardScaler())])),\n",
       "                                  ('text_features',\n",
       "                                   Pipeline(steps=[('selector',\n",
       "                                                    FunctionTransformer(func=<function <lambda> at 0x7fe6202fa1f0>)),\n",
       "                                                   ('cvec',\n",
       "                                                    CountVectorizer(stop_words='english'))]))])),\n",
       "  ('xg',\n",
       "   XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                 gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                 learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "                 random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "                 scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                 validate_parameters=None, verbosity=None))],\n",
       " 'verbose': False,\n",
       " 'features': FeatureUnion(transformer_list=[('numeric_features',\n",
       "                                 Pipeline(steps=[('selector',\n",
       "                                                  FunctionTransformer(func=<function <lambda> at 0x7fe62923bd30>)),\n",
       "                                                 ('ss', StandardScaler())])),\n",
       "                                ('text_features',\n",
       "                                 Pipeline(steps=[('selector',\n",
       "                                                  FunctionTransformer(func=<function <lambda> at 0x7fe6202fa1f0>)),\n",
       "                                                 ('cvec',\n",
       "                                                  CountVectorizer(stop_words='english'))]))]),\n",
       " 'xg': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "               gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "               random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "               scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "               validate_parameters=None, verbosity=None),\n",
       " 'features__n_jobs': None,\n",
       " 'features__transformer_list': [('numeric_features',\n",
       "   Pipeline(steps=[('selector',\n",
       "                    FunctionTransformer(func=<function <lambda> at 0x7fe62923bd30>)),\n",
       "                   ('ss', StandardScaler())])),\n",
       "  ('text_features',\n",
       "   Pipeline(steps=[('selector',\n",
       "                    FunctionTransformer(func=<function <lambda> at 0x7fe6202fa1f0>)),\n",
       "                   ('cvec', CountVectorizer(stop_words='english'))]))],\n",
       " 'features__transformer_weights': None,\n",
       " 'features__verbose': False,\n",
       " 'features__numeric_features': Pipeline(steps=[('selector',\n",
       "                  FunctionTransformer(func=<function <lambda> at 0x7fe62923bd30>)),\n",
       "                 ('ss', StandardScaler())]),\n",
       " 'features__text_features': Pipeline(steps=[('selector',\n",
       "                  FunctionTransformer(func=<function <lambda> at 0x7fe6202fa1f0>)),\n",
       "                 ('cvec', CountVectorizer(stop_words='english'))]),\n",
       " 'features__numeric_features__memory': None,\n",
       " 'features__numeric_features__steps': [('selector',\n",
       "   FunctionTransformer(func=<function <lambda> at 0x7fe62923bd30>)),\n",
       "  ('ss', StandardScaler())],\n",
       " 'features__numeric_features__verbose': False,\n",
       " 'features__numeric_features__selector': FunctionTransformer(func=<function <lambda> at 0x7fe62923bd30>),\n",
       " 'features__numeric_features__ss': StandardScaler(),\n",
       " 'features__numeric_features__selector__accept_sparse': False,\n",
       " 'features__numeric_features__selector__check_inverse': True,\n",
       " 'features__numeric_features__selector__func': <function __main__.<lambda>(df)>,\n",
       " 'features__numeric_features__selector__inv_kw_args': None,\n",
       " 'features__numeric_features__selector__inverse_func': None,\n",
       " 'features__numeric_features__selector__kw_args': None,\n",
       " 'features__numeric_features__selector__validate': False,\n",
       " 'features__numeric_features__ss__copy': True,\n",
       " 'features__numeric_features__ss__with_mean': True,\n",
       " 'features__numeric_features__ss__with_std': True,\n",
       " 'features__text_features__memory': None,\n",
       " 'features__text_features__steps': [('selector',\n",
       "   FunctionTransformer(func=<function <lambda> at 0x7fe6202fa1f0>)),\n",
       "  ('cvec', CountVectorizer(stop_words='english'))],\n",
       " 'features__text_features__verbose': False,\n",
       " 'features__text_features__selector': FunctionTransformer(func=<function <lambda> at 0x7fe6202fa1f0>),\n",
       " 'features__text_features__cvec': CountVectorizer(stop_words='english'),\n",
       " 'features__text_features__selector__accept_sparse': False,\n",
       " 'features__text_features__selector__check_inverse': True,\n",
       " 'features__text_features__selector__func': <function __main__.<lambda>(df)>,\n",
       " 'features__text_features__selector__inv_kw_args': None,\n",
       " 'features__text_features__selector__inverse_func': None,\n",
       " 'features__text_features__selector__kw_args': None,\n",
       " 'features__text_features__selector__validate': False,\n",
       " 'features__text_features__cvec__analyzer': 'word',\n",
       " 'features__text_features__cvec__binary': False,\n",
       " 'features__text_features__cvec__decode_error': 'strict',\n",
       " 'features__text_features__cvec__dtype': numpy.int64,\n",
       " 'features__text_features__cvec__encoding': 'utf-8',\n",
       " 'features__text_features__cvec__input': 'content',\n",
       " 'features__text_features__cvec__lowercase': True,\n",
       " 'features__text_features__cvec__max_df': 1.0,\n",
       " 'features__text_features__cvec__max_features': None,\n",
       " 'features__text_features__cvec__min_df': 1,\n",
       " 'features__text_features__cvec__ngram_range': (1, 1),\n",
       " 'features__text_features__cvec__preprocessor': None,\n",
       " 'features__text_features__cvec__stop_words': 'english',\n",
       " 'features__text_features__cvec__strip_accents': None,\n",
       " 'features__text_features__cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'features__text_features__cvec__tokenizer': None,\n",
       " 'features__text_features__cvec__vocabulary': None,\n",
       " 'xg__objective': 'binary:logistic',\n",
       " 'xg__base_score': None,\n",
       " 'xg__booster': None,\n",
       " 'xg__colsample_bylevel': None,\n",
       " 'xg__colsample_bynode': None,\n",
       " 'xg__colsample_bytree': None,\n",
       " 'xg__gamma': None,\n",
       " 'xg__gpu_id': None,\n",
       " 'xg__importance_type': 'gain',\n",
       " 'xg__interaction_constraints': None,\n",
       " 'xg__learning_rate': None,\n",
       " 'xg__max_delta_step': None,\n",
       " 'xg__max_depth': None,\n",
       " 'xg__min_child_weight': None,\n",
       " 'xg__missing': nan,\n",
       " 'xg__monotone_constraints': None,\n",
       " 'xg__n_estimators': 100,\n",
       " 'xg__n_jobs': None,\n",
       " 'xg__num_parallel_tree': None,\n",
       " 'xg__random_state': None,\n",
       " 'xg__reg_alpha': None,\n",
       " 'xg__reg_lambda': None,\n",
       " 'xg__scale_pos_weight': None,\n",
       " 'xg__subsample': None,\n",
       " 'xg__tree_method': None,\n",
       " 'xg__validate_parameters': None,\n",
       " 'xg__verbosity': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_responses = ['y_accomodation', 'y_arrests', 'y_beatings', 'y_crowd_dispersal', 'y_ignore', 'y_killings', 'y_shootings']\n",
    "\n",
    "region_list = dict(df[\"region\"].value_counts()).keys()\n",
    "\n",
    "country_list = dict(df[\"country\"].value_counts()).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: Europe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9952619843924192, 'Testing score': 0.9189640768588136, 'Baseline': 0.9220480668756531}, {'Response': 'y_arrests', 'Training score': 0.9779821627647715, 'Testing score': 0.9189640768588136, 'Baseline': 0.8854754440961338}, {'Response': 'y_beatings', 'Training score': 0.9913600891861761, 'Testing score': 0.9649122807017544, 'Baseline': 0.967816091954023}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9738015607580826, 'Testing score': 0.8863826232247285, 'Baseline': 0.7684430512016719}, {'Response': 'y_ignore', 'Training score': 0.9885730211817169, 'Testing score': 0.8295739348370927, 'Baseline': 0.6764890282131661}, {'Response': 'y_killings', 'Training score': 0.999721293199554, 'Testing score': 0.9933166248955723, 'Baseline': 0.9928944618599791}, {'Response': 'y_shootings', 'Training score': 0.9988851727982163, 'Testing score': 0.9916457811194653, 'Baseline': 0.9914315569487984}]\n",
      "\n",
      "Region: Africa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9977954144620811, 'Testing score': 0.8890356671070013, 'Baseline': 0.8733884297520661}, {'Response': 'y_arrests', 'Training score': 0.972663139329806, 'Testing score': 0.9009247027741083, 'Baseline': 0.8320661157024793}, {'Response': 'y_beatings', 'Training score': 0.9805996472663139, 'Testing score': 0.9379128137384413, 'Baseline': 0.9226446280991736}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9977954144620811, 'Testing score': 0.8137384412153237, 'Baseline': 0.5639669421487603}, {'Response': 'y_ignore', 'Training score': 0.9748677248677249, 'Testing score': 0.7820343461030383, 'Baseline': 0.5857851239669422}, {'Response': 'y_killings', 'Training score': 0.9991181657848325, 'Testing score': 0.9273447820343461, 'Baseline': 0.8981818181818182}, {'Response': 'y_shootings', 'Training score': 0.9986772486772487, 'Testing score': 0.9075297225891678, 'Baseline': 0.871404958677686}]\n",
      "\n",
      "Region: Asia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9439295644114921, 'Testing score': 0.8833333333333333, 'Baseline': 0.8756080611535789}, {'Response': 'y_arrests', 'Training score': 0.9295644114921223, 'Testing score': 0.8472222222222222, 'Baseline': 0.8485059068797776}, {'Response': 'y_beatings', 'Training score': 0.9768303985171455, 'Testing score': 0.9333333333333333, 'Baseline': 0.9204308547602502}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9647822057460612, 'Testing score': 0.7819444444444444, 'Baseline': 0.7029186935371786}, {'Response': 'y_ignore', 'Training score': 0.9629286376274329, 'Testing score': 0.7277777777777777, 'Baseline': 0.5059068797776234}, {'Response': 'y_killings', 'Training score': 0.9745134383688601, 'Testing score': 0.9402777777777778, 'Baseline': 0.9444058373870744}, {'Response': 'y_shootings', 'Training score': 0.9772937905468025, 'Testing score': 0.9486111111111111, 'Baseline': 0.9503127171646977}]\n",
      "\n",
      "Region: South America\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9525021204410518, 'Testing score': 0.8854961832061069, 'Baseline': 0.8867684478371501}, {'Response': 'y_arrests', 'Training score': 0.9745547073791349, 'Testing score': 0.8651399491094147, 'Baseline': 0.8842239185750637}, {'Response': 'y_beatings', 'Training score': 0.993214588634436, 'Testing score': 0.9821882951653944, 'Baseline': 0.9872773536895675}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9100932994062765, 'Testing score': 0.8040712468193384, 'Baseline': 0.6762086513994912}, {'Response': 'y_ignore', 'Training score': 0.8736217133163698, 'Testing score': 0.7557251908396947, 'Baseline': 0.5674300254452926}, {'Response': 'y_killings', 'Training score': 0.9711620016963528, 'Testing score': 0.9312977099236641, 'Baseline': 0.9472010178117048}, {'Response': 'y_shootings', 'Training score': 0.9957591178965225, 'Testing score': 0.9465648854961832, 'Baseline': 0.9713740458015268}]\n",
      "\n",
      "Region: MENA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9889025893958077, 'Testing score': 0.8966789667896679, 'Baseline': 0.9168207024029575}, {'Response': 'y_arrests', 'Training score': 0.9852034525277436, 'Testing score': 0.8560885608856088, 'Baseline': 0.8428835489833642}, {'Response': 'y_beatings', 'Training score': 0.969173859432799, 'Testing score': 0.8966789667896679, 'Baseline': 0.9131238447319778}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9815043156596794, 'Testing score': 0.7564575645756457, 'Baseline': 0.6913123844731978}, {'Response': 'y_ignore', 'Training score': 0.93711467324291, 'Testing score': 0.7822878228782287, 'Baseline': 0.5600739371534196}, {'Response': 'y_killings', 'Training score': 0.9938347718865598, 'Testing score': 0.8856088560885609, 'Baseline': 0.8826247689463955}, {'Response': 'y_shootings', 'Training score': 0.9889025893958077, 'Testing score': 0.8671586715867159, 'Baseline': 0.8706099815157117}]\n",
      "\n",
      "Region: North America\n",
      "[{'Response': 'y_accomodation', 'Training score': 1.0, 'Testing score': 0.8629032258064516, 'Baseline': 0.9107505070993915}, {'Response': 'y_arrests', 'Training score': 0.975609756097561, 'Testing score': 0.9596774193548387, 'Baseline': 0.8113590263691683}, {'Response': 'y_beatings', 'Training score': 0.997289972899729, 'Testing score': 0.967741935483871, 'Baseline': 0.973630831643002}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9701897018970189, 'Testing score': 0.8467741935483871, 'Baseline': 0.8093306288032455}, {'Response': 'y_ignore', 'Training score': 0.9376693766937669, 'Testing score': 0.75, 'Baseline': 0.5760649087221096}, {'Response': 'y_killings', 'Training score': 1.0, 'Testing score': 0.9516129032258065, 'Baseline': 0.9574036511156186}, {'Response': 'y_shootings', 'Training score': 0.9701897018970189, 'Testing score': 0.9112903225806451, 'Baseline': 0.9127789046653144}]\n",
      "\n",
      "Region: Central America\n",
      "[{'Response': 'y_accomodation', 'Training score': 0.9781931464174455, 'Testing score': 0.9166666666666666, 'Baseline': 0.916083916083916}, {'Response': 'y_arrests', 'Training score': 0.9657320872274143, 'Testing score': 0.8888888888888888, 'Baseline': 0.8834498834498834}, {'Response': 'y_beatings', 'Training score': 0.9968847352024922, 'Testing score': 0.9537037037037037, 'Baseline': 0.9673659673659674}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9906542056074766, 'Testing score': 0.8240740740740741, 'Baseline': 0.6899766899766899}, {'Response': 'y_ignore', 'Training score': 1.0, 'Testing score': 0.8240740740740741, 'Baseline': 0.5990675990675991}, {'Response': 'y_killings', 'Training score': 0.9844236760124611, 'Testing score': 0.9444444444444444, 'Baseline': 0.9533799533799534}, {'Response': 'y_shootings', 'Training score': 0.9968847352024922, 'Testing score': 0.8703703703703703, 'Baseline': 0.8834498834498834}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/47745288/how-to-featureunion-numerical-and-text-features-in-python-sklearn-properly\n",
    "# Since we are working with both numeric and text data, we had to incorporate FeatureUnion to handle two seaparate data types.\n",
    "\n",
    "def protest_by_the_response(df, response):\n",
    "    X = df[['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions', 'notes']]\n",
    "\n",
    "    y = df[response]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions']], validate=False)\n",
    "\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('log', LogisticRegression(max_iter=5000))\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "        'log__penalty' : ['l2', 'l1'],\n",
    "#         'log__C' : [0.001, 0.01, 0,1, 1, 5],\n",
    "#         'features__text_features__cvec__max_df': [0.90, 0.95],\n",
    "#         'features__text_features__cvec__max_features': [None, 1000, 3000, 5000],\n",
    "        'log__solver' : ['liblinear']\n",
    "        \n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "    \n",
    "    reg_response_dict = {\n",
    "        \"Response\": response,\n",
    "        \"Training score\": gs.score(X_train, y_train),\n",
    "        \"Testing score\": gs.score(X_test, y_test),\n",
    "        \"Baseline\": baseline\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict\n",
    "\n",
    "def responses_by_location(loc_df):\n",
    "    return [protest_by_the_response(loc_df, response) for response in possible_responses]\n",
    "\n",
    "def df_by_region(df, region):\n",
    "    return df[df[\"region\"]==region]\n",
    "\n",
    "def df_by_country(df, country):\n",
    "    return df[df[\"country\"]==country]\n",
    "\n",
    "for region in region_list:\n",
    "    #Instead of printing, append lists of dictionaries to a dataframe\n",
    "    print(f\"Region: {region}\")\n",
    "    print(responses_by_location(df_by_region(df, region)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: Europe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9292084726867336, 'Testing score': 0.9298245614035088, 'Baseline': 0.9220480668756531}, {'Response': 'y_arrests', 'Training score': 0.899108138238573, 'Testing score': 0.8847117794486216, 'Baseline': 0.8854754440961338}, {'Response': 'y_beatings', 'Training score': 0.967391304347826, 'Testing score': 0.9699248120300752, 'Baseline': 0.967816091954023}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9041248606465998, 'Testing score': 0.8671679197994987, 'Baseline': 0.7684430512016719}, {'Response': 'y_ignore', 'Training score': 0.8729096989966555, 'Testing score': 0.8387635756056808, 'Baseline': 0.6764890282131661}, {'Response': 'y_killings', 'Training score': 0.9933110367892977, 'Testing score': 0.9916457811194653, 'Baseline': 0.9928944618599791}, {'Response': 'y_shootings', 'Training score': 0.9908026755852842, 'Testing score': 0.9933166248955723, 'Baseline': 0.9914315569487984}]\n",
      "\n",
      "Region: Africa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9215167548500882, 'Testing score': 0.8824306472919419, 'Baseline': 0.8733884297520661}, {'Response': 'y_arrests', 'Training score': 0.9021164021164021, 'Testing score': 0.8295904887714664, 'Baseline': 0.8320661157024793}, {'Response': 'y_beatings', 'Training score': 0.9347442680776014, 'Testing score': 0.9194187582562747, 'Baseline': 0.9226446280991736}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9210758377425045, 'Testing score': 0.8309114927344782, 'Baseline': 0.5639669421487603}, {'Response': 'y_ignore', 'Training score': 0.9241622574955908, 'Testing score': 0.8203434610303831, 'Baseline': 0.5857851239669422}, {'Response': 'y_killings', 'Training score': 0.9320987654320988, 'Testing score': 0.9194187582562747, 'Baseline': 0.8981818181818182}, {'Response': 'y_shootings', 'Training score': 0.9188712522045855, 'Testing score': 0.8745046235138706, 'Baseline': 0.871404958677686}]\n",
      "\n",
      "Region: Asia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9036144578313253, 'Testing score': 0.8736111111111111, 'Baseline': 0.8756080611535789}, {'Response': 'y_arrests', 'Training score': 0.8725671918443003, 'Testing score': 0.875, 'Baseline': 0.8485059068797776}, {'Response': 'y_beatings', 'Training score': 0.928174235403151, 'Testing score': 0.9277777777777778, 'Baseline': 0.9204308547602502}, {'Response': 'y_crowd_dispersal', 'Training score': 0.891566265060241, 'Testing score': 0.7958333333333333, 'Baseline': 0.7029186935371786}, {'Response': 'y_ignore', 'Training score': 0.8883225208526413, 'Testing score': 0.7569444444444444, 'Baseline': 0.5059068797776234}, {'Response': 'y_killings', 'Training score': 0.9531974050046339, 'Testing score': 0.9402777777777778, 'Baseline': 0.9444058373870744}, {'Response': 'y_shootings', 'Training score': 0.9531974050046339, 'Testing score': 0.9416666666666667, 'Baseline': 0.9503127171646977}]\n",
      "\n",
      "Region: South America\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9219677692960135, 'Testing score': 0.8905852417302799, 'Baseline': 0.8867684478371501}, {'Response': 'y_arrests', 'Training score': 0.9372349448685326, 'Testing score': 0.8702290076335878, 'Baseline': 0.8842239185750637}, {'Response': 'y_beatings', 'Training score': 0.9881255301102629, 'Testing score': 0.9923664122137404, 'Baseline': 0.9872773536895675}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9321458863443596, 'Testing score': 0.8473282442748091, 'Baseline': 0.6762086513994912}, {'Response': 'y_ignore', 'Training score': 0.9296013570822731, 'Testing score': 0.8244274809160306, 'Baseline': 0.5674300254452926}, {'Response': 'y_killings', 'Training score': 0.9626802374893978, 'Testing score': 0.9465648854961832, 'Baseline': 0.9472010178117048}, {'Response': 'y_shootings', 'Training score': 0.9770992366412213, 'Testing score': 0.9694656488549618, 'Baseline': 0.9713740458015268}]\n",
      "\n",
      "Region: MENA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.969173859432799, 'Testing score': 0.9188191881918819, 'Baseline': 0.9168207024029575}, {'Response': 'y_arrests', 'Training score': 0.967940813810111, 'Testing score': 0.8745387453874539, 'Baseline': 0.8428835489833642}, {'Response': 'y_beatings', 'Training score': 0.9099876695437731, 'Testing score': 0.922509225092251, 'Baseline': 0.9131238447319778}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9630086313193588, 'Testing score': 0.7896678966789668, 'Baseline': 0.6913123844731978}, {'Response': 'y_ignore', 'Training score': 0.9926017262638718, 'Testing score': 0.7859778597785978, 'Baseline': 0.5600739371534196}, {'Response': 'y_killings', 'Training score': 0.9630086313193588, 'Testing score': 0.8634686346863468, 'Baseline': 0.8826247689463955}, {'Response': 'y_shootings', 'Training score': 0.9568434032059187, 'Testing score': 0.8450184501845018, 'Baseline': 0.8706099815157117}]\n",
      "\n",
      "Region: North America\n",
      "[{'Response': 'y_accomodation', 'Training score': 0.994579945799458, 'Testing score': 0.9112903225806451, 'Baseline': 0.9107505070993915}, {'Response': 'y_arrests', 'Training score': 0.994579945799458, 'Testing score': 0.8064516129032258, 'Baseline': 0.8113590263691683}, {'Response': 'y_beatings', 'Training score': 0.997289972899729, 'Testing score': 0.9919354838709677, 'Baseline': 0.973630831643002}, {'Response': 'y_crowd_dispersal', 'Training score': 0.989159891598916, 'Testing score': 0.8629032258064516, 'Baseline': 0.8093306288032455}, {'Response': 'y_ignore', 'Training score': 0.8265582655826558, 'Testing score': 0.7983870967741935, 'Baseline': 0.5760649087221096}, {'Response': 'y_killings', 'Training score': 0.994579945799458, 'Testing score': 0.9596774193548387, 'Baseline': 0.9574036511156186}, {'Response': 'y_shootings', 'Training score': 0.997289972899729, 'Testing score': 0.8951612903225806, 'Baseline': 0.9127789046653144}]\n",
      "\n",
      "Region: Central America\n",
      "[{'Response': 'y_accomodation', 'Training score': 0.9968847352024922, 'Testing score': 0.8981481481481481, 'Baseline': 0.916083916083916}, {'Response': 'y_arrests', 'Training score': 0.9937694704049844, 'Testing score': 0.9074074074074074, 'Baseline': 0.8834498834498834}, {'Response': 'y_beatings', 'Training score': 0.9937694704049844, 'Testing score': 0.9722222222222222, 'Baseline': 0.9673659673659674}, {'Response': 'y_crowd_dispersal', 'Training score': 1.0, 'Testing score': 0.8796296296296297, 'Baseline': 0.6899766899766899}, {'Response': 'y_ignore', 'Training score': 1.0, 'Testing score': 0.8240740740740741, 'Baseline': 0.5990675990675991}, {'Response': 'y_killings', 'Training score': 0.9906542056074766, 'Testing score': 0.9537037037037037, 'Baseline': 0.9533799533799534}, {'Response': 'y_shootings', 'Training score': 0.9968847352024922, 'Testing score': 0.8888888888888888, 'Baseline': 0.8834498834498834}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def protest_by_the_response(df, response):\n",
    "    X = df[['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions', 'notes']]\n",
    "\n",
    "    y = df[response]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions']], validate=False)\n",
    "\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('rf', RandomForestClassifier())\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "        'rf__ccp_alpha' : [0.001, 0.01, 0.1, 1, 5],\n",
    "#         'rf__n_estimators' : [100, 300, 500],\n",
    "#         'rf__max_depth' : [None, 1, 2, 3],\n",
    "#         'rf__min_samples_split' : [2, 3, 4],\n",
    "#         'rf__min_samples_leaf' : [1, 2, 3]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "    \n",
    "    reg_response_dict = {\n",
    "        \"Response\": response,\n",
    "        \"Training score\": gs.score(X_train, y_train),\n",
    "        \"Testing score\": gs.score(X_test, y_test),\n",
    "        \"Baseline\": baseline\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict\n",
    "\n",
    "def responses_by_location(loc_df):\n",
    "    return [protest_by_the_response(loc_df, response) for response in possible_responses]\n",
    "\n",
    "def df_by_region(df, region):\n",
    "    return df[df[\"region\"]==region]\n",
    "\n",
    "def df_by_country(df, country):\n",
    "    return df[df[\"country\"]==country]\n",
    "\n",
    "for region in region_list:\n",
    "    #Instead of printing, append lists of dictionaries to a dataframe\n",
    "    print(f\"Region: {region}\")\n",
    "    print(responses_by_location(df_by_region(df, region)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: Europe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9952619843924192, 'Testing score': 0.9398496240601504, 'Baseline': 0.9220480668756531}, {'Response': 'y_arrests', 'Training score': 0.9896878483835005, 'Testing score': 0.9214703425229741, 'Baseline': 0.8854754440961338}, {'Response': 'y_beatings', 'Training score': 0.9969342251950948, 'Testing score': 0.9690893901420217, 'Baseline': 0.967816091954023}, {'Response': 'y_crowd_dispersal', 'Training score': 0.991917502787068, 'Testing score': 0.8964076858813701, 'Baseline': 0.7684430512016719}, {'Response': 'y_ignore', 'Training score': 0.9835562987736901, 'Testing score': 0.8437761069340016, 'Baseline': 0.6764890282131661}, {'Response': 'y_killings', 'Training score': 0.9927536231884058, 'Testing score': 0.9933166248955723, 'Baseline': 0.9928944618599791}, {'Response': 'y_shootings', 'Training score': 0.9983277591973244, 'Testing score': 0.9908103592314118, 'Baseline': 0.9914315569487984}]\n",
      "\n",
      "Region: Africa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9951499118165785, 'Testing score': 0.8863936591809776, 'Baseline': 0.8733884297520661}, {'Response': 'y_arrests', 'Training score': 0.9916225749559083, 'Testing score': 0.9101717305151915, 'Baseline': 0.8320661157024793}, {'Response': 'y_beatings', 'Training score': 0.996031746031746, 'Testing score': 0.9326287978863936, 'Baseline': 0.9226446280991736}, {'Response': 'y_crowd_dispersal', 'Training score': 0.941358024691358, 'Testing score': 0.8243064729194187, 'Baseline': 0.5639669421487603}, {'Response': 'y_ignore', 'Training score': 0.9947089947089947, 'Testing score': 0.7833553500660502, 'Baseline': 0.5857851239669422}, {'Response': 'y_killings', 'Training score': 0.9964726631393298, 'Testing score': 0.9220607661822986, 'Baseline': 0.8981818181818182}, {'Response': 'y_shootings', 'Training score': 0.9955908289241623, 'Testing score': 0.8877146631439894, 'Baseline': 0.871404958677686}]\n",
      "\n",
      "Region: Asia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9666357738646896, 'Testing score': 0.8972222222222223, 'Baseline': 0.8756080611535789}, {'Response': 'y_arrests', 'Training score': 0.9527340129749768, 'Testing score': 0.8597222222222223, 'Baseline': 0.8485059068797776}, {'Response': 'y_beatings', 'Training score': 0.9777571825764597, 'Testing score': 0.9375, 'Baseline': 0.9204308547602502}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9596848934198332, 'Testing score': 0.7958333333333333, 'Baseline': 0.7029186935371786}, {'Response': 'y_ignore', 'Training score': 0.9337349397590361, 'Testing score': 0.8041666666666667, 'Baseline': 0.5059068797776234}, {'Response': 'y_killings', 'Training score': 0.9443929564411492, 'Testing score': 0.9444444444444444, 'Baseline': 0.9444058373870744}, {'Response': 'y_shootings', 'Training score': 0.9485634847080631, 'Testing score': 0.9555555555555556, 'Baseline': 0.9503127171646977}]\n",
      "\n",
      "Region: South America\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9491094147582697, 'Testing score': 0.9007633587786259, 'Baseline': 0.8867684478371501}, {'Response': 'y_arrests', 'Training score': 0.9618320610687023, 'Testing score': 0.8982188295165394, 'Baseline': 0.8842239185750637}, {'Response': 'y_beatings', 'Training score': 0.9864291772688719, 'Testing score': 0.989821882951654, 'Baseline': 0.9872773536895675}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9016115351993215, 'Testing score': 0.8091603053435115, 'Baseline': 0.6762086513994912}, {'Response': 'y_ignore', 'Training score': 0.910941475826972, 'Testing score': 0.7837150127226463, 'Baseline': 0.5674300254452926}, {'Response': 'y_killings', 'Training score': 0.9397794741306191, 'Testing score': 0.9694656488549618, 'Baseline': 0.9472010178117048}, {'Response': 'y_shootings', 'Training score': 0.9711620016963528, 'Testing score': 0.9720101781170484, 'Baseline': 0.9713740458015268}]\n",
      "\n",
      "Region: MENA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9161528976572133, 'Testing score': 0.922509225092251, 'Baseline': 0.9168207024029575}, {'Response': 'y_arrests', 'Training score': 0.9815043156596794, 'Testing score': 0.8523985239852399, 'Baseline': 0.8428835489833642}, {'Response': 'y_beatings', 'Training score': 0.9802712700369913, 'Testing score': 0.8966789667896679, 'Baseline': 0.9131238447319778}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9728729963008631, 'Testing score': 0.8007380073800738, 'Baseline': 0.6913123844731978}, {'Response': 'y_ignore', 'Training score': 0.9778051787916153, 'Testing score': 0.7712177121771218, 'Baseline': 0.5600739371534196}, {'Response': 'y_killings', 'Training score': 0.9901356350184957, 'Testing score': 0.8892988929889298, 'Baseline': 0.8826247689463955}, {'Response': 'y_shootings', 'Training score': 0.9753390875462392, 'Testing score': 0.9003690036900369, 'Baseline': 0.8706099815157117}]\n",
      "\n",
      "Region: North America\n",
      "[{'Response': 'y_accomodation', 'Training score': 0.9105691056910569, 'Testing score': 0.9112903225806451, 'Baseline': 0.9107505070993915}, {'Response': 'y_arrests', 'Training score': 0.991869918699187, 'Testing score': 0.9032258064516129, 'Baseline': 0.8113590263691683}, {'Response': 'y_beatings', 'Training score': 0.983739837398374, 'Testing score': 0.9435483870967742, 'Baseline': 0.973630831643002}, {'Response': 'y_crowd_dispersal', 'Training score': 0.986449864498645, 'Testing score': 0.8306451612903226, 'Baseline': 0.8093306288032455}, {'Response': 'y_ignore', 'Training score': 0.9186991869918699, 'Testing score': 0.7661290322580645, 'Baseline': 0.5760649087221096}, {'Response': 'y_killings', 'Training score': 0.959349593495935, 'Testing score': 0.9516129032258065, 'Baseline': 0.9574036511156186}, {'Response': 'y_shootings', 'Training score': 0.9105691056910569, 'Testing score': 0.9193548387096774, 'Baseline': 0.9127789046653144}]\n",
      "\n",
      "Region: Central America\n",
      "[{'Response': 'y_accomodation', 'Training score': 0.9096573208722741, 'Testing score': 0.9351851851851852, 'Baseline': 0.916083916083916}, {'Response': 'y_arrests', 'Training score': 0.897196261682243, 'Testing score': 0.8425925925925926, 'Baseline': 0.8834498834498834}, {'Response': 'y_beatings', 'Training score': 0.9657320872274143, 'Testing score': 0.9722222222222222, 'Baseline': 0.9673659673659674}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9376947040498442, 'Testing score': 0.7314814814814815, 'Baseline': 0.6899766899766899}, {'Response': 'y_ignore', 'Training score': 0.9968847352024922, 'Testing score': 0.7037037037037037, 'Baseline': 0.5990675990675991}, {'Response': 'y_killings', 'Training score': 0.9532710280373832, 'Testing score': 0.9537037037037037, 'Baseline': 0.9533799533799534}, {'Response': 'y_shootings', 'Training score': 0.9968847352024922, 'Testing score': 0.8611111111111112, 'Baseline': 0.8834498834498834}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def protest_by_the_response(df, response):\n",
    "    X = df[['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions', 'notes']]\n",
    "\n",
    "    y = df[response]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions']], validate=False)\n",
    "\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('svc', SVC())\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "        'svc__C' : [0.001, 0.01, 0.1, 1, 5],\n",
    "        'svc__degree' :[2,3,4],\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "    \n",
    "    reg_response_dict = {\n",
    "        \"Response\": response,\n",
    "        \"Training score\": gs.score(X_train, y_train),\n",
    "        \"Testing score\": gs.score(X_test, y_test),\n",
    "        \"Baseline\": baseline\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict\n",
    "\n",
    "def responses_by_location(loc_df):\n",
    "    return [protest_by_the_response(loc_df, response) for response in possible_responses]\n",
    "\n",
    "def df_by_region(df, region):\n",
    "    return df[df[\"region\"]==region]\n",
    "\n",
    "def df_by_country(df, country):\n",
    "    return df[df[\"country\"]==country]\n",
    "\n",
    "for region in region_list:\n",
    "    #Instead of printing, append lists of dictionaries to a dataframe\n",
    "    print(f\"Region: {region}\")\n",
    "    print(responses_by_location(df_by_region(df, region)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'xg__objective': 'binary:logistic',\n",
    "#  'xg__base_score': None,\n",
    "#  'xg__booster': None,\n",
    "#  'xg__colsample_bylevel': None,\n",
    "#  'xg__colsample_bynode': None,\n",
    "#  'xg__colsample_bytree': None,\n",
    "#  'xg__gamma': None,\n",
    "#  'xg__gpu_id': None,\n",
    "#  'xg__importance_type': 'gain',\n",
    "#  'xg__interaction_constraints': None,\n",
    "#  'xg__learning_rate': None,\n",
    "#  'xg__max_delta_step': None,\n",
    "#  'xg__max_depth': None,\n",
    "#  'xg__min_child_weight': None,\n",
    "#  'xg__missing': nan,\n",
    "#  'xg__monotone_constraints': None,\n",
    "#  'xg__n_estimators': 100,\n",
    "#  'xg__n_jobs': None,\n",
    "#  'xg__num_parallel_tree': None,\n",
    "#  'xg__random_state': None,\n",
    "#  'xg__reg_alpha': None,\n",
    "#  'xg__reg_lambda': None,\n",
    "#  'xg__scale_pos_weight': None,\n",
    "#  'xg__subsample': None,\n",
    "#  'xg__tree_method': None,\n",
    "#  'xg__validate_parameters': None,\n",
    "#  'xg__verbosity': None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: Europe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9431438127090301, 'Testing score': 0.9289891395154553, 'Baseline': 0.9220480668756531}, {'Response': 'y_arrests', 'Training score': 0.9526198439241917, 'Testing score': 0.9373433583959899, 'Baseline': 0.8854754440961338}, {'Response': 'y_beatings', 'Training score': 0.9986064659977704, 'Testing score': 0.9715956558061821, 'Baseline': 0.967816091954023}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9629319955406912, 'Testing score': 0.8897243107769424, 'Baseline': 0.7684430512016719}, {'Response': 'y_ignore', 'Training score': 0.9311594202898551, 'Testing score': 0.8529657477025898, 'Baseline': 0.6764890282131661}, {'Response': 'y_killings', 'Training score': 0.9955406911928651, 'Testing score': 0.9866332497911445, 'Baseline': 0.9928944618599791}, {'Response': 'y_shootings', 'Training score': 0.999721293199554, 'Testing score': 0.9908103592314118, 'Baseline': 0.9914315569487984}]\n",
      "\n",
      "Region: Africa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9761904761904762, 'Testing score': 0.8877146631439894, 'Baseline': 0.8733884297520661}, {'Response': 'y_arrests', 'Training score': 0.9722222222222222, 'Testing score': 0.9075297225891678, 'Baseline': 0.8320661157024793}, {'Response': 'y_beatings', 'Training score': 0.9854497354497355, 'Testing score': 0.9299867899603699, 'Baseline': 0.9226446280991736}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9651675485008818, 'Testing score': 0.8243064729194187, 'Baseline': 0.5639669421487603}, {'Response': 'y_ignore', 'Training score': 0.8619929453262787, 'Testing score': 0.8150594451783355, 'Baseline': 0.5857851239669422}, {'Response': 'y_killings', 'Training score': 1.0, 'Testing score': 0.9247027741083224, 'Baseline': 0.8981818181818182}, {'Response': 'y_shootings', 'Training score': 0.9554673721340388, 'Testing score': 0.9009247027741083, 'Baseline': 0.871404958677686}]\n",
      "\n",
      "Region: Asia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9443929564411492, 'Testing score': 0.8694444444444445, 'Baseline': 0.8756080611535789}, {'Response': 'y_arrests', 'Training score': 0.8739573679332715, 'Testing score': 0.8625, 'Baseline': 0.8485059068797776}, {'Response': 'y_beatings', 'Training score': 0.968952734012975, 'Testing score': 0.9333333333333333, 'Baseline': 0.9204308547602502}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9253938832252085, 'Testing score': 0.7861111111111111, 'Baseline': 0.7029186935371786}, {'Response': 'y_ignore', 'Training score': 0.8243744207599629, 'Testing score': 0.775, 'Baseline': 0.5059068797776234}, {'Response': 'y_killings', 'Training score': 0.9670991658943466, 'Testing score': 0.9513888888888888, 'Baseline': 0.9444058373870744}, {'Response': 'y_shootings', 'Training score': 0.9541241890639481, 'Testing score': 0.9430555555555555, 'Baseline': 0.9503127171646977}]\n",
      "\n",
      "Region: South America\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9380831212892281, 'Testing score': 0.8982188295165394, 'Baseline': 0.8867684478371501}, {'Response': 'y_arrests', 'Training score': 0.9499575911789653, 'Testing score': 0.9134860050890585, 'Baseline': 0.8842239185750637}, {'Response': 'y_beatings', 'Training score': 0.9881255301102629, 'Testing score': 0.9847328244274809, 'Baseline': 0.9872773536895675}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9448685326547922, 'Testing score': 0.8524173027989822, 'Baseline': 0.6762086513994912}, {'Response': 'y_ignore', 'Training score': 0.905852417302799, 'Testing score': 0.7659033078880407, 'Baseline': 0.5674300254452926}, {'Response': 'y_killings', 'Training score': 0.9669211195928753, 'Testing score': 0.9465648854961832, 'Baseline': 0.9472010178117048}, {'Response': 'y_shootings', 'Training score': 0.9940627650551315, 'Testing score': 0.9796437659033079, 'Baseline': 0.9713740458015268}]\n",
      "\n",
      "Region: MENA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/young_park/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Response': 'y_accomodation', 'Training score': 0.9704069050554871, 'Testing score': 0.9114391143911439, 'Baseline': 0.9168207024029575}, {'Response': 'y_arrests', 'Training score': 0.8939580764488286, 'Testing score': 0.8634686346863468, 'Baseline': 0.8428835489833642}, {'Response': 'y_beatings', 'Training score': 0.9605425400739828, 'Testing score': 0.9188191881918819, 'Baseline': 0.9131238447319778}, {'Response': 'y_crowd_dispersal', 'Training score': 0.9753390875462392, 'Testing score': 0.8413284132841329, 'Baseline': 0.6913123844731978}, {'Response': 'y_ignore', 'Training score': 0.87422934648582, 'Testing score': 0.8154981549815498, 'Baseline': 0.5600739371534196}, {'Response': 'y_killings', 'Training score': 0.9815043156596794, 'Testing score': 0.8929889298892989, 'Baseline': 0.8826247689463955}, {'Response': 'y_shootings', 'Training score': 0.9013563501849569, 'Testing score': 0.8708487084870848, 'Baseline': 0.8706099815157117}]\n",
      "\n",
      "Region: North America\n",
      "[{'Response': 'y_accomodation', 'Training score': 0.9539295392953929, 'Testing score': 0.8467741935483871, 'Baseline': 0.9107505070993915}, {'Response': 'y_arrests', 'Training score': 0.964769647696477, 'Testing score': 0.9274193548387096, 'Baseline': 0.8113590263691683}, {'Response': 'y_beatings', 'Training score': 0.981029810298103, 'Testing score': 0.9032258064516129, 'Baseline': 0.973630831643002}, {'Response': 'y_crowd_dispersal', 'Training score': 0.994579945799458, 'Testing score': 0.7903225806451613, 'Baseline': 0.8093306288032455}, {'Response': 'y_ignore', 'Training score': 0.8780487804878049, 'Testing score': 0.75, 'Baseline': 0.5760649087221096}, {'Response': 'y_killings', 'Training score': 0.986449864498645, 'Testing score': 0.9596774193548387, 'Baseline': 0.9574036511156186}, {'Response': 'y_shootings', 'Training score': 0.8915989159891599, 'Testing score': 0.8951612903225806, 'Baseline': 0.9127789046653144}]\n",
      "\n",
      "Region: Central America\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-dc81f409aa1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m#Instead of printing, append lists of dictionaries to a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Region: {region}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses_by_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_by_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-dc81f409aa1e>\u001b[0m in \u001b[0;36mresponses_by_location\u001b[0;34m(loc_df)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresponses_by_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprotest_by_the_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossible_responses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdf_by_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-dc81f409aa1e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresponses_by_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprotest_by_the_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossible_responses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdf_by_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-dc81f409aa1e>\u001b[0m in \u001b[0;36mprotest_by_the_response\u001b[0;34m(df, response)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    826\u001b[0m                                 missing=self.missing, nthread=self.n_jobs)\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m         self._Booster = train(xgb_options, train_dmatrix,\n\u001b[0m\u001b[1;32m    829\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                               \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     return _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    209\u001b[0m                            \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1160\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def protest_by_the_response(df, response):\n",
    "    X = df[['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions', 'notes']]\n",
    "\n",
    "    y = df[response]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions']], validate=False)\n",
    "\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('xg', XGBClassifier())\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "        'xg__gamma' : [0.001, 0.01, 0.1, 1, 5],\n",
    "        'xg__max_depth' :[None, 2, 3],\n",
    "        'xg__learning_rate' : [0.001, 0.01, 0.1, 1, 5]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "    \n",
    "    reg_response_dict = {\n",
    "        \"Response\": response,\n",
    "        \"Training score\": gs.score(X_train, y_train),\n",
    "        \"Testing score\": gs.score(X_test, y_test),\n",
    "        \"Baseline\": baseline\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict\n",
    "\n",
    "def responses_by_location(loc_df):\n",
    "    return [protest_by_the_response(loc_df, response) for response in possible_responses]\n",
    "\n",
    "def df_by_region(df, region):\n",
    "    return df[df[\"region\"]==region]\n",
    "\n",
    "def df_by_country(df, country):\n",
    "    return df[df[\"country\"]==country]\n",
    "\n",
    "for region in region_list:\n",
    "    #Instead of printing, append lists of dictionaries to a dataframe\n",
    "    print(f\"Region: {region}\")\n",
    "    print(responses_by_location(df_by_region(df, region)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: Europe\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions 1 and 3588 are not compatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-54b559cc98f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m#Instead of printing, append lists of dictionaries to a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Region: {region}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses_by_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_by_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-54b559cc98f3>\u001b[0m in \u001b[0;36mresponses_by_location\u001b[0;34m(loc_df)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresponses_by_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprotest_by_the_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossible_responses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdf_by_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-54b559cc98f3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresponses_by_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprotest_by_the_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossible_responses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdf_by_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-54b559cc98f3>\u001b[0m in \u001b[0;36mprotest_by_the_response\u001b[0;34m(df, response)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \"\"\"\n\u001b[0;32m--> 682\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   3008\u001b[0m         self._tensors[0].get_shape()[0]))\n\u001b[1;32m   3009\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3010\u001b[0;31m       batch_dim.assert_is_compatible_with(tensor_shape.Dimension(\n\u001b[0m\u001b[1;32m   3011\u001b[0m           tensor_shape.dimension_value(t.get_shape()[0])))\n\u001b[1;32m   3012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \"\"\"\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m       raise ValueError(\"Dimensions %s and %s are not compatible\" %\n\u001b[0m\u001b[1;32m    280\u001b[0m                        (self, other))\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions 1 and 3588 are not compatible"
     ]
    }
   ],
   "source": [
    "def protest_by_the_response(df, response):\n",
    "    X = df[['notes']]\n",
    "    y = df[response]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    def fnn(hl_1=32, hl_2=16, d1=0.5, d2=0.5):\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(hl_1, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "        model.add(Dropout(d1))\n",
    "        \n",
    "        model.add(Dense(hl_2, activation='relu'))\n",
    "        model.add(Dropout(d2))\n",
    "        \n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.compile(loss='bce', optimizer='adam')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    fnn_model = KerasClassifier(fnn, epochs=10, batch_size=512, verbose=0)\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('cvec', CountVectorizer(stop_words='english')),\n",
    "        ('fnn', fnn_model)])\n",
    "    \n",
    "    params = {\n",
    "        'fnn__epochs' :[10, 30, 50]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "    \n",
    "    reg_response_dict = {\n",
    "        \"Response\": response,\n",
    "        \"Training score\": gs.score(X_train, y_train),\n",
    "        \"Testing score\": gs.score(X_test, y_test),\n",
    "        \"Baseline\": baseline\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict\n",
    "\n",
    "def responses_by_location(loc_df):\n",
    "    return [protest_by_the_response(loc_df, response) for response in possible_responses]\n",
    "\n",
    "def df_by_region(df, region):\n",
    "    return df[df[\"region\"]==region]\n",
    "\n",
    "def df_by_country(df, country):\n",
    "    return df[df[\"country\"]==country]\n",
    "\n",
    "for region in region_list:\n",
    "    #Instead of printing, append lists of dictionaries to a dataframe\n",
    "    print(f\"Region: {region}\")\n",
    "    print(responses_by_location(df_by_region(df, region)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['notes']]\n",
    "y = df['y_ignore']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "def fnn(hl_1=32):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(h1_1, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='bce', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "fnn_model = KerasClassifier(fnn, epochs=10, batch_size=512, verbose=0)\n",
    "\n",
    "\n",
    "pipe = Pipeline([(\n",
    "'cvec', CountVectorizer(stop_words='english')),\n",
    "('fnn', fnn_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec', CountVectorizer(stop_words='english')),\n",
       "  ('fnn',\n",
       "   <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier at 0x7fe6107cde80>)],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(stop_words='english'),\n",
       " 'fnn': <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier at 0x7fe6107cde80>,\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': 'english',\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': None,\n",
       " 'cvec__vocabulary': None,\n",
       " 'fnn__epochs': 10,\n",
       " 'fnn__batch_size': 512,\n",
       " 'fnn__verbose': 0,\n",
       " 'fnn__build_fn': <function __main__.fnn(hl_1=32)>}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
